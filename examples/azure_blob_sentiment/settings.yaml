# ELSPETH Azure Blob Sentiment Analysis Example
#
# End-to-end Azure pipeline: reads from Azure Blob Storage, checks content safety,
# analyzes sentiment using Azure OpenAI, and writes results back to Azure Blob Storage.
# Flagged content is routed to a separate sink.
#
# Prerequisites:
#   # Azure OpenAI
#   export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
#   export AZURE_OPENAI_KEY="your-openai-api-key"
#   export AZURE_OPENAI_DEPLOYMENT="your-gpt-deployment-name"
#   export AZURE_OPENAI_API_VERSION="2024-12-01-preview"
#
#   # Azure Content Safety
#   export AZURE_CONTENT_SAFETY_ENDPOINT="https://your-resource.cognitiveservices.azure.com"
#   export AZURE_CONTENT_SAFETY_KEY="your-content-safety-key"
#
#   # Azure Storage (SAS token auth)
#   export AZURE_STORAGE_ACCOUNT_URL="https://youraccount.blob.core.windows.net"
#   export AZURE_STORAGE_SAS_TOKEN="sv=2022-11-02&ss=b&srt=sco&sp=rwdlacyx..."
#   export AZURE_STORAGE_CONTAINER="elspeth-demo"
#
# Run with:
#   uv run elspeth run -s examples/azure_blob_sentiment/settings.yaml --execute

source:
  plugin: azure_blob
  options:
    sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
    account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
    container: "${AZURE_STORAGE_CONTAINER}"
    blob_path: "input/sentiment_data.csv"
    format: csv
    csv_options:
      delimiter: ","
      has_header: true
      encoding: utf-8
    schema:
      mode: strict
      fields:
        - "id: int"
        - "text: str"
    on_validation_failure: discard

transforms:
  # Step 1: Filter blocked keywords (fast, local check)
  - plugin: keyword_filter
    options:
      fields: text
      blocked_patterns:
        - "(?i)\\bpineapple\\b"  # Case-insensitive word match
      on_error: blocked_keywords
      schema:
        fields: dynamic

  # Step 2: Check content safety before sending to LLM
  - plugin: azure_content_safety
    options:
      endpoint: "${AZURE_CONTENT_SAFETY_ENDPOINT}"
      api_key: "${AZURE_CONTENT_SAFETY_KEY}"
      fields: text  # Analyze the 'text' field
      thresholds:
        hate: 2      # Block moderate+ hate speech
        violence: 2  # Block moderate+ violence
        sexual: 2    # Block moderate+ sexual content
        self_harm: 0 # Block any self-harm content
      on_error: flagged  # Route flagged content to 'flagged' sink
      schema:
        fields: dynamic
      pool_size: 5  # Process 5 rows concurrently

  # Step 3: Check for prompt injection attacks
  - plugin: azure_prompt_shield
    options:
      endpoint: "${AZURE_CONTENT_SAFETY_ENDPOINT}"
      api_key: "${AZURE_CONTENT_SAFETY_KEY}"
      fields: text  # Analyze the 'text' field
      on_error: attacks  # Route detected attacks to 'attacks' sink
      schema:
        fields: dynamic
      pool_size: 5  # Process 5 rows concurrently

  # Step 4: Analyze sentiment (only for content that passed all safety checks)
  - plugin: azure_llm
    options:
      deployment_name: "${AZURE_OPENAI_DEPLOYMENT}"
      endpoint: "${AZURE_OPENAI_ENDPOINT}"
      api_key: "${AZURE_OPENAI_KEY}"
      api_version: "${AZURE_OPENAI_API_VERSION}"
      template: |
        Analyze the sentiment of the following text and respond with ONLY a JSON object.

        Text: {{ row.text }}

        Respond with exactly this format (no other text):
        {"sentiment": "positive" or "negative" or "neutral", "confidence": 0.0-1.0, "summary": "brief explanation"}
      temperature: 0.0
      response_field: sentiment_analysis
      on_error: llm_errors  # Route LLM failures to 'llm_errors' sink
      schema:
        fields: dynamic
      pool_size: 10  # Process 10 rows concurrently

sinks:
  # Main output - safe content with sentiment analysis
  output:
    plugin: azure_blob
    options:
      sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
      account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
      container: "${AZURE_STORAGE_CONTAINER}"
      blob_path: "output/{{ run_id }}/results.csv"
      format: csv
      overwrite: true
      csv_options:
        delimiter: ","
        encoding: utf-8
        include_header: true
      schema:
        fields: dynamic

  # Flagged content - content that failed content safety check (hate, violence, sexual, self-harm)
  flagged:
    plugin: azure_blob
    options:
      sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
      account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
      container: "${AZURE_STORAGE_CONTAINER}"
      blob_path: "output/{{ run_id }}/flagged.csv"
      format: csv
      overwrite: true
      csv_options:
        delimiter: ","
        encoding: utf-8
        include_header: true
      schema:
        fields: dynamic

  # Attacks - content that failed prompt injection detection (jailbreaks, prompt injection)
  attacks:
    plugin: azure_blob
    options:
      sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
      account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
      container: "${AZURE_STORAGE_CONTAINER}"
      blob_path: "output/{{ run_id }}/attacks.csv"
      format: csv
      overwrite: true
      csv_options:
        delimiter: ","
        encoding: utf-8
        include_header: true
      schema:
        fields: dynamic

  # Blocked keywords - content matching blocked word patterns
  blocked_keywords:
    plugin: azure_blob
    options:
      sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
      account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
      container: "${AZURE_STORAGE_CONTAINER}"
      blob_path: "output/{{ run_id }}/blocked_keywords.csv"
      format: csv
      overwrite: true
      csv_options:
        delimiter: ","
        encoding: utf-8
        include_header: true
      schema:
        fields: dynamic

  # LLM errors - rows that failed during sentiment analysis
  llm_errors:
    plugin: azure_blob
    options:
      sas_token: "${AZURE_STORAGE_SAS_TOKEN}"
      account_url: "${AZURE_STORAGE_ACCOUNT_URL}"
      container: "${AZURE_STORAGE_CONTAINER}"
      blob_path: "output/{{ run_id }}/llm_errors.csv"
      format: csv
      overwrite: true
      csv_options:
        delimiter: ","
        encoding: utf-8
        include_header: true
      schema:
        fields: dynamic

default_sink: output

# Audit trail stored locally
landscape:
  url: sqlite:///examples/azure_blob_sentiment/runs/audit.db
