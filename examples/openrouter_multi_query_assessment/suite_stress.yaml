# STRESS TEST: 500 rows × 10 queries = 5000 LLM calls at pool_size 30
# Expect to hit rate limits and observe AIMD backoff behavior

source:
  plugin: csv
  options:
    path: examples/openrouter_multi_query_assessment/input_500.csv
    schema:
      mode: free
      fields:
        - "user_id: str"
        - "cs1_background: str"
        - "cs1_symptoms: str"
        - "cs1_history: str"
        - "cs2_background: str"
        - "cs2_symptoms: str"
        - "cs2_history: str"
    on_validation_failure: discard

transforms:
  - plugin: openrouter_multi_query_llm
    options:
      model: "anthropic/claude-3-5-sonnet"
      api_key: "${OPENROUTER_API_KEY}"

      system_prompt: |
        You are a medical assessment AI. For each case study and criterion,
        provide a score (0-100) and rationale. Respond ONLY in JSON format:
        {"score": <number>, "rationale": "<explanation>"}

      template: |
        ## Case Study
        **Background:** {{ row.input_1 }}
        **Symptoms:** {{ row.input_2 }}
        **History:** {{ row.input_3 }}

        ## Evaluation Criterion: {{ row.criterion.name }}
        {{ row.criterion.description }}

        {% if row.criterion.subcriteria %}
        Consider these subcriteria:
        {% for sub in row.criterion.subcriteria %}
        - {{ sub }}
        {% endfor %}
        {% endif %}

        Provide your assessment.

      lookup_file: criteria_lookup.yaml

      # Multi-query plugin generates input_1/2/3 and criterion from case_studies × criteria
      required_input_fields: []  # Opt-out: fields are generated dynamically by plugin

      case_studies:
        - name: cs1
          input_fields: [cs1_background, cs1_symptoms, cs1_history]
        - name: cs2
          input_fields: [cs2_background, cs2_symptoms, cs2_history]

      criteria:
        - name: diagnosis
          code: DIAG
          description: "Assess the accuracy and completeness of the diagnosis"
          subcriteria:
            - Correct primary diagnosis
            - Appropriate differential diagnoses considered
            - Evidence-based reasoning
        - name: treatment
          code: TREAT
          description: "Assess the appropriateness of the treatment plan"
          subcriteria:
            - Guideline-concordant treatment
            - Patient-specific considerations
            - Risk-benefit analysis
        - name: prognosis
          code: PROG
          description: "Assess the accuracy of prognostic assessment"
          subcriteria:
            - Realistic timeline
            - Key prognostic factors identified
            - Clear communication
        - name: risk
          code: RISK
          description: "Assess identification of risks and complications"
          subcriteria:
            - Comprehensive risk identification
            - Appropriate severity assessment
            - Mitigation strategies
        - name: followup
          code: FOLLOW
          description: "Assess the follow-up and monitoring plan"
          subcriteria:
            - Appropriate follow-up timeline
            - Clear monitoring parameters
            - Escalation criteria defined

      response_format: standard
      output_mapping:
        score:
          suffix: score
          type: integer
        rationale:
          suffix: rationale
          type: string

      # HIGH CONCURRENCY for stress test
      pool_size: 30
      temperature: 0.0
      max_tokens: 300  # Shorter to speed up

      schema:
        fields: dynamic

sinks:
  output:
    plugin: csv
    options:
      path: examples/openrouter_multi_query_assessment/output/results_stress.csv
      schema:
        fields: dynamic

default_sink: output

landscape:
  url: sqlite:///examples/openrouter_multi_query_assessment/runs/audit_stress.db
