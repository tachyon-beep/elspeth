# ELSPETH Schema Contracts LLM Assessment Example
#
# This pipeline demonstrates Unified Schema Contracts with LLM transforms.
# The input CSV has intentionally "crazy" headers that get normalized:
#
# Original headers:
#   User ID #                      -> user_id
#   Case Study 1 - Background Info -> case_study_1_background_info
#   CS1: Symptoms & Signs          -> cs1_symptoms_signs
#   CS1 >> Medical History         -> cs1_medical_history
#   Case Study 2 - Background Info -> case_study_2_background_info
#   CS2: Symptoms & Signs!!        -> cs2_symptoms_signs
#   CS2 >> Medical History         -> cs2_medical_history
#
# The pipeline:
# 1. Reads messy CSV headers and normalizes them
# 2. Sends each case study to OpenRouter LLM for assessment
# 3. Records the full schema contract in the audit trail
# 4. Output uses normalized field names
#
# Prerequisites:
#   export OPENROUTER_API_KEY="your-openrouter-api-key"
#
# Run with:
#   uv run elspeth run -s examples/schema_contracts_llm_assessment/settings.yaml --execute
#
# After running, inspect the audit trail:
#   uv run elspeth-mcp --database sqlite:///examples/schema_contracts_llm_assessment/runs/audit.db
#
# Then query the field mappings:
#   > get_run_contract("<run_id>")
#   > explain_field("<run_id>", "cs1_symptoms_signs")

source:
  plugin: csv
  options:
    path: examples/schema_contracts_llm_assessment/input.csv
    schema:
      # OBSERVED mode: infer schema from first row
      # The contract will capture BOTH original crazy names AND normalized names
      mode: observed
    # Enable automatic header normalization
    normalize_fields: true
    on_validation_failure: discard

transforms:
  - plugin: openrouter_multi_query_llm
    options:
      # OpenRouter model
      model: "anthropic/claude-3-5-sonnet"
      api_key: "${OPENROUTER_API_KEY}"

      system_prompt: |
        You are a medical assessment AI. For each case study and criterion,
        provide a score (0-100) and rationale. Respond ONLY in JSON format:
        {"score": <number>, "rationale": "<explanation>"}

      template: |
        ## Case Study
        **Background:** {{ row.input_1 }}
        **Symptoms:** {{ row.input_2 }}
        **History:** {{ row.input_3 }}

        ## Evaluation Criterion: {{ row.criterion.name }}
        {{ row.criterion.description }}

        {% if row.criterion.subcriteria %}
        Consider these subcriteria:
        {% for sub in row.criterion.subcriteria %}
        - {{ sub }}
        {% endfor %}
        {% endif %}

        Provide your assessment.

      lookup_file: criteria_lookup.yaml

      # Multi-query plugin generates input_1/2/3 and criterion from case_studies x criteria
      required_input_fields: []  # Opt-out: fields are generated dynamically by plugin

      # Reference fields using NORMALIZED names!
      # Original: "Case Study 1 - Background Info" -> Normalized: case_study_1_background_info
      case_studies:
        - name: cs1
          input_fields:
            - case_study_1_background_info   # Was: "Case Study 1 - Background Info"
            - cs1_symptoms_signs              # Was: 'CS1: Symptoms & Signs'
            - cs1_medical_history             # Was: "CS1 >> Medical History"
        - name: cs2
          input_fields:
            - case_study_2_background_info   # Was: "  Case Study 2 - Background Info  "
            - cs2_symptoms_signs              # Was: 'CS2: Symptoms & Signs!!'
            - cs2_medical_history             # Was: """CS2 >> Medical History"""

      criteria:
        - name: diagnosis
          code: DIAG
          description: "Assess the accuracy and completeness of the diagnosis"
          subcriteria:
            - Correct primary diagnosis
            - Appropriate differential diagnoses considered
            - Evidence-based reasoning
        - name: treatment
          code: TREAT
          description: "Assess the appropriateness of the treatment plan"
          subcriteria:
            - Guideline-concordant treatment
            - Patient-specific considerations
            - Risk-benefit analysis
        - name: prognosis
          code: PROG
          description: "Assess the accuracy of prognostic assessment"
          subcriteria:
            - Realistic timeline
            - Key prognostic factors identified
            - Clear communication

      response_format: standard
      output_mapping:
        score:
          suffix: score
          type: integer
        rationale:
          suffix: rationale
          type: string

      pool_size: 5
      temperature: 0.0
      max_tokens: 500

      schema:
        mode: observed

sinks:
  output:
    plugin: csv
    options:
      path: examples/schema_contracts_llm_assessment/output/results.csv
      schema:
        mode: observed

default_sink: output

landscape:
  url: sqlite:///examples/schema_contracts_llm_assessment/runs/audit.db
