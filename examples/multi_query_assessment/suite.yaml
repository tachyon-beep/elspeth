# ELSPETH Multi-Query Case Study Assessment Example
#
# This pipeline reads case studies from a CSV, evaluates each against multiple
# criteria using Azure OpenAI, and outputs assessment scores and rationales.
#
# Prerequisites:
#   export AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com"
#   export AZURE_OPENAI_KEY="your-api-key-here"
#   export AZURE_OPENAI_DEPLOYMENT="your-gpt-deployment-name"
#
# Run with:
#   uv run elspeth run -s examples/multi_query_assessment/suite.yaml --execute

name: case_study_assessment
description: Assess multiple case studies against multiple criteria

source:
  plugin: csv_source
  options:
    path: examples/multi_query_assessment/input.csv
    schema:
      fields:
        - name: user_id
          type: string
        - name: cs1_background
          type: string
        - name: cs1_symptoms
          type: string
        - name: cs1_history
          type: string
        - name: cs2_background
          type: string
        - name: cs2_symptoms
          type: string
        - name: cs2_history
          type: string

transforms:
  - plugin: azure_multi_query_llm
    options:
      deployment_name: "${AZURE_OPENAI_DEPLOYMENT}"
      endpoint: "${AZURE_OPENAI_ENDPOINT}"
      api_key: "${AZURE_OPENAI_KEY}"

      system_prompt: |
        You are a medical assessment AI. For each case study and criterion,
        provide a score (0-100) and rationale. Respond ONLY in JSON format:
        {"score": <number>, "rationale": "<explanation>"}

      template: |
        ## Case Study
        **Background:** {{ input_1 }}
        **Symptoms:** {{ input_2 }}
        **History:** {{ input_3 }}

        ## Evaluation Criterion: {{ criterion.name }}
        {{ criterion.description }}

        {% if criterion.subcriteria %}
        Consider these subcriteria:
        {% for sub in criterion.subcriteria %}
        - {{ sub }}
        {% endfor %}
        {% endif %}

        Provide your assessment.

      lookup_file: criteria_lookup.yaml

      case_studies:
        - name: cs1
          input_fields: [cs1_background, cs1_symptoms, cs1_history]
        - name: cs2
          input_fields: [cs2_background, cs2_symptoms, cs2_history]

      criteria:
        - name: diagnosis
          code: DIAG
          description: "Assess the accuracy and completeness of the diagnosis"
          subcriteria:
            - Correct primary diagnosis
            - Appropriate differential diagnoses considered
            - Evidence-based reasoning
        - name: treatment
          code: TREAT
          description: "Assess the appropriateness of the treatment plan"
          subcriteria:
            - Guideline-concordant treatment
            - Patient-specific considerations
            - Risk-benefit analysis
        - name: prognosis
          code: PROG
          description: "Assess the accuracy of prognostic assessment"
          subcriteria:
            - Realistic timeline
            - Key prognostic factors identified
            - Clear communication
        - name: risk
          code: RISK
          description: "Assess identification of risks and complications"
          subcriteria:
            - Comprehensive risk identification
            - Appropriate severity assessment
            - Mitigation strategies
        - name: followup
          code: FOLLOW
          description: "Assess the follow-up and monitoring plan"
          subcriteria:
            - Appropriate follow-up timeline
            - Clear monitoring parameters
            - Escalation criteria defined

      response_format: json
      output_mapping:
        score: score
        rationale: rationale

      pool_size: 10
      temperature: 0.0
      max_tokens: 500

      schema:
        fields: dynamic

sinks:
  - name: results
    plugin: csv_sink
    options:
      path: examples/multi_query_assessment/output/results.csv
