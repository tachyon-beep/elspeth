"""E2E tests for concurrent resume and edge-case resume scenarios.

Tests verify that resume operations are correctly rejected when
inappropriate: completed runs, non-existent runs, and runs without
checkpoints.

Uses file-based SQLite and real payload stores. No mocks except
external services.
"""

from __future__ import annotations

from datetime import UTC, datetime
from pathlib import Path
from typing import Any

from elspeth.contracts import (
    Determinism,
    NodeType,
    RunStatus,
)
from elspeth.contracts.contract_records import ContractAuditRecord
from elspeth.contracts.schema_contract import FieldContract, SchemaContract
from elspeth.core.checkpoint import CheckpointManager, RecoveryManager
from elspeth.core.dag import ExecutionGraph
from elspeth.core.landscape.database import LandscapeDB
from elspeth.core.landscape.schema import (
    nodes_table,
    rows_table,
    runs_table,
    tokens_table,
)
from elspeth.core.payload_store import FilesystemPayloadStore
from elspeth.engine.orchestrator import Orchestrator, PipelineConfig
from tests.fixtures.base_classes import as_sink, as_source
from tests.fixtures.pipeline import build_linear_pipeline
from tests.fixtures.plugins import CollectSink, ListSource

# ---------------------------------------------------------------------------
# Shared helpers
# ---------------------------------------------------------------------------


def _create_test_schema_contract() -> tuple[str, str]:
    """Create a minimal schema contract for test runs.

    Returns:
        Tuple of (schema_contract_json, schema_contract_hash)
    """
    field_contracts = (
        FieldContract(
            normalized_name="id",
            original_name="id",
            python_type=int,
            required=True,
            source="declared",
        ),
        FieldContract(
            normalized_name="value",
            original_name="value",
            python_type=int,
            required=True,
            source="declared",
        ),
    )
    contract = SchemaContract(fields=field_contracts, mode="FIXED", locked=True)
    audit_record = ContractAuditRecord.from_contract(contract)
    return audit_record.to_json(), contract.version_hash()


class TestConcurrentResume:
    """Tests for resume rejection scenarios."""

    def test_second_resume_of_completed_run_rejected(self, tmp_path: Path) -> None:
        """Run pipeline, let it complete, try to resume.

        Verify can_resume() returns False for completed runs.
        """
        db = LandscapeDB(f"sqlite:///{tmp_path}/audit.db")
        payload_store = FilesystemPayloadStore(tmp_path / "payloads")

        source_data = [{"id": i, "value": i * 10} for i in range(3)]
        source = ListSource(source_data)
        sink = CollectSink("default")

        config = PipelineConfig(
            source=as_source(source),
            transforms=[],
            sinks={"default": as_sink(sink)},
        )

        # Use from_plugin_instances() for production-path fidelity
        _source_for_graph, _transforms, _sinks, graph = build_linear_pipeline(source_data)

        orchestrator = Orchestrator(db)
        result = orchestrator.run(config, graph=graph, payload_store=payload_store)

        assert result.status == RunStatus.COMPLETED

        # Try to resume the completed run
        checkpoint_mgr = CheckpointManager(db)
        recovery_mgr = RecoveryManager(db, checkpoint_mgr)

        check = recovery_mgr.can_resume(result.run_id, graph)
        assert check.can_resume is False
        assert "completed" in check.reason.lower()

        db.close()

    def test_resume_of_non_existent_run_rejected(self, tmp_path: Path) -> None:
        """Try to resume a run_id that doesn't exist.

        Verify can_resume() returns False with appropriate reason.
        """
        db = LandscapeDB(f"sqlite:///{tmp_path}/audit.db")

        checkpoint_mgr = CheckpointManager(db)
        recovery_mgr = RecoveryManager(db, checkpoint_mgr)

        # Build a minimal graph for the can_resume call
        # NOTE: Manual ExecutionGraph construction is acceptable here
        # because we are testing resume rejection, not pipeline execution.
        # No checkpoint or pipeline data exists for this fake run_id.
        graph = ExecutionGraph()
        schema_config: dict[str, Any] = {"schema": {"mode": "observed"}}
        graph.add_node(
            "source",
            node_type=NodeType.SOURCE,
            plugin_name="test",
            config=schema_config,
        )

        check = recovery_mgr.can_resume("non-existent-run-id-12345", graph)
        assert check.can_resume is False
        assert "not found" in check.reason.lower()

        db.close()

    def test_resume_without_checkpoint_rejected(self, tmp_path: Path) -> None:
        """Create a failed run without any checkpoint.

        Verify can_resume() returns False because there is no checkpoint
        to resume from.
        """
        db = LandscapeDB(f"sqlite:///{tmp_path}/audit.db")

        run_id = "failed-no-checkpoint-run"
        now = datetime.now(UTC)
        contract_json, contract_hash = _create_test_schema_contract()

        # Create a failed run with rows but NO checkpoint
        with db.engine.connect() as conn:
            conn.execute(
                runs_table.insert().values(
                    run_id=run_id,
                    started_at=now,
                    config_hash="test",
                    settings_json="{}",
                    canonical_version="sha256-rfc8785-v1",
                    status=RunStatus.FAILED,
                    schema_contract_json=contract_json,
                    schema_contract_hash=contract_hash,
                )
            )

            conn.execute(
                nodes_table.insert().values(
                    node_id="source",
                    run_id=run_id,
                    plugin_name="test_source",
                    node_type=NodeType.SOURCE,
                    plugin_version="1.0",
                    determinism=Determinism.DETERMINISTIC,
                    config_hash="test",
                    config_json="{}",
                    registered_at=now,
                )
            )

            # Create a row so the run has data
            conn.execute(
                rows_table.insert().values(
                    row_id="row-000",
                    run_id=run_id,
                    source_node_id="source",
                    row_index=0,
                    source_data_hash="hash-0",
                    created_at=now,
                )
            )
            conn.execute(
                tokens_table.insert().values(
                    token_id="tok-000",
                    row_id="row-000",
                    created_at=now,
                )
            )
            conn.commit()

        # No checkpoint was created

        checkpoint_mgr = CheckpointManager(db)
        recovery_mgr = RecoveryManager(db, checkpoint_mgr)

        # Build a minimal graph for the can_resume call
        graph = ExecutionGraph()
        schema_config_dict: dict[str, Any] = {"schema": {"mode": "observed"}}
        graph.add_node(
            "source",
            node_type=NodeType.SOURCE,
            plugin_name="test_source",
            config=schema_config_dict,
        )

        check = recovery_mgr.can_resume(run_id, graph)
        assert check.can_resume is False
        assert "checkpoint" in check.reason.lower()

        db.close()
