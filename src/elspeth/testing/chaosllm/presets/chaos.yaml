# ChaosLLM Preset: chaos
# Purpose: Everything breaks constantly - maximum stress testing.
# Use when: Testing resilience, error handling coverage, failure recovery.
# WARNING: Not suitable for performance measurements - too much noise.

server:
  host: "127.0.0.1"
  port: 8000
  workers: 4

metrics:
  database: "file:chaosllm-metrics?mode=memory&cache=shared"
  timeseries_bucket_sec: 1

response:
  mode: random
  random:
    min_words: 5
    max_words: 200
    vocabulary: english

latency:
  base_ms: 100
  jitter_ms: 100

error_injection:
  # Scaled to ~25% total errors (was 40%, multiplied by 0.625)
  # High HTTP error rates across all types
  rate_limit_pct: 6.25
  capacity_529_pct: 3.125
  service_unavailable_pct: 1.875
  retry_after_sec: [1, 10]

  # Server errors
  internal_error_pct: 1.875
  bad_gateway_pct: 1.25
  gateway_timeout_pct: 1.25

  # Client errors
  forbidden_pct: 0.625
  not_found_pct: 0.625

  # Connection-level failures
  timeout_pct: 1.25
  timeout_sec: [15, 45]
  connection_reset_pct: 0.9375
  slow_response_pct: 1.875
  slow_response_sec: [10, 30]

  # Malformed responses
  invalid_json_pct: 1.25
  truncated_pct: 0.9375
  empty_body_pct: 0.625
  missing_fields_pct: 0.9375
  wrong_content_type_pct: 0.3125

  # Aggressive bursts
  burst:
    enabled: true
    interval_sec: 20
    duration_sec: 8
    rate_limit_pct: 90
    capacity_pct: 70
