# WP-11.99: Config-Driven Plugin Schemas

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Replace hardcoded `extra="allow"` schemas with mandatory config-driven schema definitions, making schema choices auditable and enabling runtime validation.

**Architecture:** Every plugin that processes row data must declare `schema` in config. Two options: `fields: dynamic` (accept anything, logged for audit) or explicit field definitions with `mode: strict` (exactly these fields) or `mode: free` (at least these fields). Type coercion happens at the source boundary; transforms and sinks expect clean data by contract.

---

## Key Architectural Decisions

### Three-Tier Trust Model Enforcement

This WP enforces ELSPETH's three-tier trust model via the `allow_coercion` parameter:

| Plugin Type | `allow_coercion` | Behavior | Rationale |
|-------------|------------------|----------|-----------|
| **Source** | `True` | Coerces `"42"` → `42` | Normalizes external data at boundary |
| **Transform** | `False` | Rejects `"42"` for `int` field | Wrong types = source bug (crash) |
| **Sink** | `False` | Rejects `"42"` for `int` field | Wrong types = transform bug (crash) |

**Why this matters:** If a transform receives a string when it expects an int, coercing silently would hide the bug. Crashing immediately surfaces it.

### Schema Modes

| Mode | `extra` Setting | Use Case |
|------|-----------------|----------|
| `dynamic` | `"allow"` | "I don't know what fields to expect" |
| `strict` | `"forbid"` | "I expect exactly these fields" |
| `free` | `"allow"` | "I need at least these fields, extras OK" |

### Validation Error Handling

Sources record validation errors to the audit trail via `ctx.record_validation_error()`:
- Invalid rows are **quarantined** (not processed further)
- Error details, row hash, and schema mode are **recorded** (complete audit coverage)
- Pipeline **continues** processing valid rows

This differs from transform/sink validation which **crashes** (wrong types = upstream bug).

---

**Tech Stack:** Python 3.12, Pydantic v2, typing

**Prior Art:**
- `PluginSchema` base class in `contracts/data.py` with `extra="ignore"`, `strict=False`
- `PluginConfig` base class in `plugins/config_base.py` with `extra="forbid"`
- 7 identical dynamic schema classes scattered across plugins (to be eliminated)

---

## Design Overview

### Schema Configuration Syntax

```yaml
# Option 1: Dynamic schema (accept anything)
plugins:
  csv_source:
    path: data.csv
    schema:
      fields: dynamic  # Logged for audit: "schema_mode: dynamic"

# Option 2: Explicit schema with strict mode (exactly these fields)
plugins:
  csv_source:
    path: data.csv
    schema:
      mode: strict      # Row must have EXACTLY these fields
      fields:
        - id: int
        - name: str
        - email: str
        - score: float?  # ? suffix = optional (nullable)

# Option 3: Explicit schema with free mode (at least these fields)
plugins:
  json_source:
    path: data.json
    schema:
      mode: free        # Row must have AT LEAST these fields (extras allowed)
      fields:
        - id: int
        - name: str
```

### Mode Semantics

| Mode | Fields | Behavior | Extra Fields |
|------|--------|----------|--------------|
| (any) | `dynamic` | Accept anything | Allowed |
| `strict` | explicit | Must match exactly | **Rejected** |
| `free` | explicit | Must have at least these | Allowed |

### Trust Boundaries

| Plugin Type | Schema Role | On Violation |
|-------------|-------------|--------------|
| **Source** | Validates + coerces THEIR DATA | Quarantine row, continue |
| **Transform** | Contract: must output valid data | Crash (OUR CODE bug) |
| **Sink** | Expects clean data | Crash (transform bug) |

### Audit Trail

Schema configuration recorded at run start:
```python
recorder.register_node(
    ...,
    schema_config={
        "mode": "strict" | "free" | "dynamic",
        "fields": [...] | None,
    }
)
```

---

## Task 1: Create Schema Configuration Types

**Files:**
- Create: `src/elspeth/contracts/schema.py`
- Test: `tests/contracts/test_schema_config.py`

**Step 1: Write failing tests for SchemaConfig**

Create `tests/contracts/test_schema_config.py`:

```python
"""Tests for schema configuration types."""

import pytest
from pydantic import ValidationError


class TestFieldDefinition:
    """Tests for FieldDefinition parsing."""

    def test_field_definition_exists(self) -> None:
        """FieldDefinition can be imported."""
        from elspeth.contracts.schema import FieldDefinition

        assert FieldDefinition is not None

    def test_parse_required_field(self) -> None:
        """Parse 'name: str' as required string field."""
        from elspeth.contracts.schema import FieldDefinition

        field = FieldDefinition.parse("name: str")
        assert field.name == "name"
        assert field.field_type == "str"
        assert field.required is True

    def test_parse_optional_field(self) -> None:
        """Parse 'score: float?' as optional float field."""
        from elspeth.contracts.schema import FieldDefinition

        field = FieldDefinition.parse("score: float?")
        assert field.name == "score"
        assert field.field_type == "float"
        assert field.required is False

    def test_parse_all_types(self) -> None:
        """All supported types parse correctly."""
        from elspeth.contracts.schema import FieldDefinition

        for type_name in ["str", "int", "float", "bool", "any"]:
            field = FieldDefinition.parse(f"field: {type_name}")
            assert field.field_type == type_name

    def test_parse_invalid_type_raises(self) -> None:
        """Invalid type raises ValueError."""
        from elspeth.contracts.schema import FieldDefinition

        with pytest.raises(ValueError, match="Unknown type"):
            FieldDefinition.parse("field: invalid")

    def test_parse_malformed_raises(self) -> None:
        """Malformed field spec raises ValueError."""
        from elspeth.contracts.schema import FieldDefinition

        with pytest.raises(ValueError, match="Invalid field"):
            FieldDefinition.parse("no_colon_here")

    def test_parse_hyphenated_field_name_raises(self) -> None:
        """Field names with hyphens raise helpful error."""
        from elspeth.contracts.schema import FieldDefinition

        with pytest.raises(ValueError, match="user_id.*instead"):
            FieldDefinition.parse("user-id: int")

    def test_parse_dotted_field_name_raises(self) -> None:
        """Field names with dots raise helpful error."""
        from elspeth.contracts.schema import FieldDefinition

        with pytest.raises(ValueError, match="data_field.*instead"):
            FieldDefinition.parse("data.field: str")


class TestSchemaConfig:
    """Tests for SchemaConfig parsing."""

    def test_schema_config_exists(self) -> None:
        """SchemaConfig can be imported."""
        from elspeth.contracts.schema import SchemaConfig

        assert SchemaConfig is not None

    def test_dynamic_schema(self) -> None:
        """Parse dynamic schema config."""
        from elspeth.contracts.schema import SchemaConfig

        config = SchemaConfig.from_dict({"fields": "dynamic"})
        assert config.is_dynamic is True
        assert config.mode is None
        assert config.fields is None

    def test_strict_schema(self) -> None:
        """Parse strict schema with explicit fields."""
        from elspeth.contracts.schema import SchemaConfig

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["id: int", "name: str"],
        })
        assert config.is_dynamic is False
        assert config.mode == "strict"
        assert len(config.fields) == 2
        assert config.fields[0].name == "id"
        assert config.fields[1].name == "name"

    def test_free_schema(self) -> None:
        """Parse free schema with explicit fields."""
        from elspeth.contracts.schema import SchemaConfig

        config = SchemaConfig.from_dict({
            "mode": "free",
            "fields": ["id: int", "name: str", "score: float?"],
        })
        assert config.is_dynamic is False
        assert config.mode == "free"
        assert len(config.fields) == 3
        assert config.fields[2].required is False

    def test_explicit_fields_require_mode(self) -> None:
        """Explicit fields without mode raises error."""
        from elspeth.contracts.schema import SchemaConfig

        with pytest.raises(ValueError, match="mode.*required"):
            SchemaConfig.from_dict({"fields": ["id: int"]})

    def test_dynamic_ignores_mode(self) -> None:
        """Dynamic fields ignores mode if provided."""
        from elspeth.contracts.schema import SchemaConfig

        config = SchemaConfig.from_dict({"fields": "dynamic", "mode": "strict"})
        assert config.is_dynamic is True
        assert config.mode is None  # Ignored

    def test_missing_fields_raises(self) -> None:
        """Missing fields key raises error."""
        from elspeth.contracts.schema import SchemaConfig

        with pytest.raises(ValueError, match="fields.*required"):
            SchemaConfig.from_dict({})

    def test_empty_fields_raises(self) -> None:
        """Empty fields list raises error."""
        from elspeth.contracts.schema import SchemaConfig

        with pytest.raises(ValueError, match="at least one field"):
            SchemaConfig.from_dict({"mode": "strict", "fields": []})
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/contracts/test_schema_config.py -v`

Expected: FAIL with `ModuleNotFoundError: No module named 'elspeth.contracts.schema'`

**Step 3: Implement FieldDefinition and SchemaConfig**

Create `src/elspeth/contracts/schema.py`:

```python
"""Schema configuration types for config-driven plugin schemas.

This module provides the configuration types that allow users to specify
plugin schemas in their pipeline configuration files. Schemas can be:

1. Dynamic: Accept any fields (logged for audit)
2. Strict: Accept exactly the specified fields (no more, no less)
3. Free: Accept at least the specified fields (extras allowed)

Example YAML:
    plugins:
      csv_source:
        path: data.csv
        schema:
          mode: strict
          fields:
            - id: int
            - name: str
            - score: float?  # Optional field
"""

from __future__ import annotations

import re
from dataclasses import dataclass, field
from typing import Literal

# Supported field types for schema definitions
SUPPORTED_TYPES = frozenset({"str", "int", "float", "bool", "any"})

# Pattern: "field_name: type" or "field_name: type?"
# Field names must be valid Python identifiers (letters, digits, underscores)
# NOTE: Hyphens and dots are NOT supported in field names
#   - "user-id: int"  -> INVALID (use "user_id: int")
#   - "data.field: str" -> INVALID (use "data_field: str")
# This is intentional: field names map to Python attributes/dict keys
FIELD_PATTERN = re.compile(r"^(\w+):\s*(str|int|float|bool|any)(\?)?$")


@dataclass(frozen=True)
class FieldDefinition:
    """Definition of a single field in a schema.

    Attributes:
        name: Field name (must be valid Python identifier)
        field_type: One of: str, int, float, bool, any
        required: If False, field can be missing or None
    """

    name: str
    field_type: Literal["str", "int", "float", "bool", "any"]
    required: bool = True

    @classmethod
    def parse(cls, spec: str) -> FieldDefinition:
        """Parse a field specification string.

        Args:
            spec: Field spec like "name: str" or "score: float?"

        Returns:
            FieldDefinition instance

        Raises:
            ValueError: If spec is malformed or type is unknown
        """
        spec = spec.strip()
        match = FIELD_PATTERN.match(spec)

        if not match:
            # Check if it's a type issue vs format issue
            if ":" in spec:
                parts = spec.split(":", 1)
                name_part = parts[0].strip()
                type_part = parts[1].strip().rstrip("?")

                # Check for invalid type
                if type_part not in SUPPORTED_TYPES:
                    raise ValueError(
                        f"Unknown type '{type_part}' in field spec '{spec}'. "
                        f"Supported types: {', '.join(sorted(SUPPORTED_TYPES))}"
                    )

                # Check for invalid field name (hyphens, dots, etc.)
                if not name_part.isidentifier():
                    raise ValueError(
                        f"Invalid field name '{name_part}' in field spec '{spec}'. "
                        f"Field names must be valid Python identifiers "
                        f"(letters, digits, underscores only). "
                        f"Use '{name_part.replace('-', '_').replace('.', '_')}' instead."
                    )

            raise ValueError(
                f"Invalid field spec '{spec}'. "
                f"Expected format: 'field_name: type' or 'field_name: type?'"
            )

        name, field_type, optional_marker = match.groups()
        return cls(
            name=name,
            field_type=field_type,  # type: ignore[arg-type]
            required=optional_marker is None,
        )

    def to_dict(self) -> dict[str, str | bool]:
        """Convert to dictionary for serialization."""
        return {
            "name": self.name,
            "type": self.field_type,
            "required": self.required,
        }


@dataclass(frozen=True)
class SchemaConfig:
    """Configuration for a plugin's data schema.

    A schema can be either dynamic (accept anything) or explicit
    (validate against specified fields).

    Attributes:
        mode: "strict" (exact fields), "free" (at least these), or None (dynamic)
        fields: List of FieldDefinitions, or None if dynamic
        is_dynamic: True if schema accepts any fields
    """

    mode: Literal["strict", "free"] | None
    fields: tuple[FieldDefinition, ...] | None
    is_dynamic: bool

    @classmethod
    def from_dict(cls, config: dict) -> SchemaConfig:
        """Parse schema configuration from dict.

        Args:
            config: Dict with 'fields' key (required) and optional 'mode'

        Returns:
            SchemaConfig instance

        Raises:
            ValueError: If config is invalid
        """
        if "fields" not in config:
            raise ValueError(
                "Schema config requires 'fields' key. "
                "Use 'fields: dynamic' or provide explicit field list."
            )

        fields_value = config["fields"]

        # Dynamic schema
        if fields_value == "dynamic":
            return cls(
                mode=None,
                fields=None,
                is_dynamic=True,
            )

        # Explicit schema - requires mode
        if "mode" not in config:
            raise ValueError(
                "Explicit schema fields require 'mode' key. "
                "Use 'mode: strict' (exactly these fields) or "
                "'mode: free' (at least these fields)."
            )

        mode = config["mode"]
        if mode not in ("strict", "free"):
            raise ValueError(
                f"Invalid schema mode '{mode}'. "
                f"Expected 'strict' or 'free'."
            )

        # Parse field list
        if not isinstance(fields_value, list):
            raise ValueError(
                f"Schema fields must be a list, got {type(fields_value).__name__}"
            )

        if len(fields_value) == 0:
            raise ValueError(
                "Schema must define at least one field. "
                "Use 'fields: dynamic' to accept any fields."
            )

        parsed_fields = tuple(FieldDefinition.parse(f) for f in fields_value)

        return cls(
            mode=mode,
            fields=parsed_fields,
            is_dynamic=False,
        )

    def to_dict(self) -> dict:
        """Convert to dictionary for audit logging.

        Note: For dynamic schemas, mode is stored as None internally but
        serialized as "dynamic" for clarity in audit logs. This is intentional:
        - Internal: mode=None, is_dynamic=True (distinguishes from explicit modes)
        - Serialized: mode="dynamic" (clear in audit trail)
        """
        if self.is_dynamic:
            return {"mode": "dynamic", "fields": None}
        return {
            "mode": self.mode,
            "fields": [f.to_dict() for f in self.fields] if self.fields else [],
        }

    @property
    def allows_extra_fields(self) -> bool:
        """Whether extra fields beyond schema are allowed."""
        return self.is_dynamic or self.mode == "free"
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/contracts/test_schema_config.py -v`

Expected: All 13 tests pass

**Step 5: Commit**

```bash
git add src/elspeth/contracts/schema.py tests/contracts/test_schema_config.py
git commit -m "$(cat <<'EOF'
feat(contracts): add SchemaConfig for config-driven plugin schemas

Adds FieldDefinition and SchemaConfig types for specifying plugin
schemas in configuration files. Supports three modes:
- dynamic: Accept any fields (logged for audit)
- strict: Accept exactly the specified fields
- free: Accept at least the specified fields

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 2: Create Schema Factory

**Files:**
- Create: `src/elspeth/plugins/schema_factory.py`
- Test: `tests/plugins/test_schema_factory.py`

**Design Note: Coercion Control**

Per the three-tier trust model:
- **Sources** MAY coerce external data (`"42"` → `42`)
- **Transforms/Sinks** MUST NOT coerce (wrong types = upstream bug)

The factory accepts `allow_coercion: bool` to enforce this distinction.

**Step 1: Write failing tests for schema factory**

Create `tests/plugins/test_schema_factory.py`:

```python
"""Tests for schema factory - creates Pydantic models from config."""

import pytest
from pydantic import ValidationError


class TestCreateSchemaFromConfig:
    """Tests for create_schema_from_config function."""

    def test_factory_exists(self) -> None:
        """Factory function can be imported."""
        from elspeth.plugins.schema_factory import create_schema_from_config

        assert create_schema_from_config is not None

    def test_dynamic_schema_accepts_anything(self) -> None:
        """Dynamic schema accepts arbitrary fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({"fields": "dynamic"})
        Schema = create_schema_from_config(config, "TestSchema")

        # Should accept any fields
        instance = Schema(foo="bar", count=42, nested={"a": 1})
        assert instance.model_dump() == {"foo": "bar", "count": 42, "nested": {"a": 1}}

    def test_strict_schema_rejects_extra_fields(self) -> None:
        """Strict schema rejects extra fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["id: int", "name: str"],
        })
        Schema = create_schema_from_config(config, "StrictSchema")

        # Should accept exact fields
        instance = Schema(id=1, name="Alice")
        assert instance.model_dump() == {"id": 1, "name": "Alice"}

        # Should reject extra fields
        with pytest.raises(ValidationError, match="extra"):
            Schema(id=1, name="Alice", extra_field="nope")

    def test_strict_schema_requires_all_fields(self) -> None:
        """Strict schema requires all non-optional fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["id: int", "name: str"],
        })
        Schema = create_schema_from_config(config, "StrictSchema")

        # Should require all fields
        with pytest.raises(ValidationError, match="name"):
            Schema(id=1)

    def test_free_schema_allows_extra_fields(self) -> None:
        """Free schema allows extra fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "free",
            "fields": ["id: int", "name: str"],
        })
        Schema = create_schema_from_config(config, "FreeSchema")

        # Should accept required + extra fields
        instance = Schema(id=1, name="Alice", extra="allowed")
        dumped = instance.model_dump()
        assert dumped["id"] == 1
        assert dumped["name"] == "Alice"
        assert dumped["extra"] == "allowed"

    def test_free_schema_requires_specified_fields(self) -> None:
        """Free schema still requires specified fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "free",
            "fields": ["id: int", "name: str"],
        })
        Schema = create_schema_from_config(config, "FreeSchema")

        # Should require specified fields
        with pytest.raises(ValidationError, match="name"):
            Schema(id=1)

    def test_optional_field_can_be_missing(self) -> None:
        """Optional fields (?) can be missing or None."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["id: int", "score: float?"],
        })
        Schema = create_schema_from_config(config, "OptionalSchema")

        # Should accept without optional field
        instance = Schema(id=1)
        assert instance.model_dump() == {"id": 1, "score": None}

        # Should accept with optional field
        instance2 = Schema(id=2, score=3.14)
        assert instance2.model_dump() == {"id": 2, "score": 3.14}

        # Should accept explicit None
        instance3 = Schema(id=3, score=None)
        assert instance3.model_dump() == {"id": 3, "score": None}

    def test_type_coercion_int_to_float(self) -> None:
        """Int values coerce to float fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["value: float"],
        })
        Schema = create_schema_from_config(config, "CoerceSchema")

        instance = Schema(value=42)  # int -> float
        assert instance.value == 42.0
        assert isinstance(instance.value, float)

    def test_type_coercion_string_to_int(self) -> None:
        """String numeric values coerce to int fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["count: int"],
        })
        Schema = create_schema_from_config(config, "CoerceSchema")

        instance = Schema(count="42")  # str -> int
        assert instance.count == 42
        assert isinstance(instance.count, int)

    def test_type_coercion_string_to_float(self) -> None:
        """String numeric values coerce to float fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["value: float"],
        })
        Schema = create_schema_from_config(config, "CoerceSchema")

        instance = Schema(value="3.14")  # str -> float
        assert instance.value == 3.14

    def test_type_coercion_string_to_bool(self) -> None:
        """String boolean values coerce to bool fields."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["active: bool"],
        })
        Schema = create_schema_from_config(config, "CoerceSchema")

        # Various truthy strings
        assert Schema(active="true").active is True
        assert Schema(active="True").active is True
        assert Schema(active="1").active is True
        assert Schema(active="yes").active is True

        # Various falsy strings
        assert Schema(active="false").active is False
        assert Schema(active="False").active is False
        assert Schema(active="0").active is False
        assert Schema(active="no").active is False

    def test_any_type_accepts_anything(self) -> None:
        """'any' type accepts any value without coercion."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["data: any"],
        })
        Schema = create_schema_from_config(config, "AnySchema")

        # Accept various types
        assert Schema(data="string").data == "string"
        assert Schema(data=42).data == 42
        assert Schema(data=[1, 2, 3]).data == [1, 2, 3]
        assert Schema(data={"nested": "dict"}).data == {"nested": "dict"}

    def test_invalid_type_not_coercible(self) -> None:
        """Non-coercible values raise ValidationError."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["count: int"],
        })
        Schema = create_schema_from_config(config, "CoerceSchema")

        with pytest.raises(ValidationError):
            Schema(count="not_a_number")


class TestCoercionControl:
    """Tests for coercion control - enforces three-tier trust model."""

    def test_coercion_enabled_by_default(self) -> None:
        """Default behavior allows coercion (for sources)."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["count: int"],
        })
        # Default: allow_coercion=True (source behavior)
        Schema = create_schema_from_config(config, "SourceSchema")

        instance = Schema(count="42")  # str -> int coercion
        assert instance.count == 42
        assert isinstance(instance.count, int)

    def test_coercion_disabled_rejects_string_to_int(self) -> None:
        """With coercion disabled, string '42' is rejected for int field."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["count: int"],
        })
        # Transforms/sinks: allow_coercion=False
        Schema = create_schema_from_config(config, "TransformSchema", allow_coercion=False)

        # Should REJECT string, not coerce
        with pytest.raises(ValidationError, match="int"):
            Schema(count="42")

    def test_coercion_disabled_rejects_string_to_float(self) -> None:
        """With coercion disabled, string '3.14' is rejected for float field."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["value: float"],
        })
        Schema = create_schema_from_config(config, "TransformSchema", allow_coercion=False)

        with pytest.raises(ValidationError, match="float"):
            Schema(value="3.14")

    def test_coercion_disabled_still_accepts_correct_types(self) -> None:
        """With coercion disabled, correct types are still accepted."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["count: int", "value: float", "name: str"],
        })
        Schema = create_schema_from_config(config, "TransformSchema", allow_coercion=False)

        # Correct types work fine
        instance = Schema(count=42, value=3.14, name="Alice")
        assert instance.count == 42
        assert instance.value == 3.14
        assert instance.name == "Alice"

    def test_coercion_disabled_allows_int_to_float(self) -> None:
        """Int -> float is allowed even without coercion (numeric widening)."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["value: float"],
        })
        Schema = create_schema_from_config(config, "TransformSchema", allow_coercion=False)

        # int -> float is always safe (widening, not coercion)
        instance = Schema(value=42)
        assert instance.value == 42.0

    def test_dynamic_schema_with_coercion_disabled(self) -> None:
        """Dynamic schema with coercion disabled still accepts any types."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({"fields": "dynamic"})
        Schema = create_schema_from_config(config, "DynamicSchema", allow_coercion=False)

        # Dynamic accepts anything - no type checking
        instance = Schema(foo="bar", count="42", value="3.14")
        assert instance.model_dump() == {"foo": "bar", "count": "42", "value": "3.14"}


class TestSchemaPluginSchemaCompliance:
    """Tests for PluginSchema compliance and conversion methods."""

    def test_schema_is_plugin_schema_subclass(self) -> None:
        """Generated schema is a PluginSchema subclass."""
        from elspeth.contracts import PluginSchema
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({"fields": "dynamic"})
        Schema = create_schema_from_config(config, "TestSchema")

        assert issubclass(Schema, PluginSchema)

    def test_to_row_returns_all_fields(self) -> None:
        """to_row() returns all fields including extras in free mode."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.schema_factory import create_schema_from_config

        config = SchemaConfig.from_dict({
            "mode": "free",
            "fields": ["id: int"],
        })
        Schema = create_schema_from_config(config, "FreeSchema")

        instance = Schema(id=1, extra="value")
        row = instance.to_row()
        assert row == {"id": 1, "extra": "value"}
```

**Step 2: Run tests to verify they fail**

Run: `pytest tests/plugins/test_schema_factory.py -v`

Expected: FAIL with `ModuleNotFoundError`

**Step 3: Implement schema factory**

Create `src/elspeth/plugins/schema_factory.py`:

```python
"""Factory for creating Pydantic schemas from configuration.

This module creates runtime Pydantic models based on SchemaConfig,
enabling config-driven schema validation for plugins.

CRITICAL: The `allow_coercion` parameter enforces the three-tier trust model:
- Sources (allow_coercion=True): May coerce "42" -> 42
- Transforms/Sinks (allow_coercion=False): Reject wrong types (upstream bug)
"""

from __future__ import annotations

from typing import Any

from pydantic import ConfigDict, create_model

from elspeth.contracts import PluginSchema
from elspeth.contracts.schema import FieldDefinition, SchemaConfig

# Python type mapping for schema field types
TYPE_MAP: dict[str, type] = {
    "str": str,
    "int": int,
    "float": float,
    "bool": bool,
    "any": Any,
}


def create_schema_from_config(
    config: SchemaConfig,
    name: str,
    allow_coercion: bool = True,
) -> type[PluginSchema]:
    """Create a Pydantic schema class from configuration.

    Args:
        config: Schema configuration specifying fields and mode
        name: Name for the generated schema class
        allow_coercion: If True, coerce types (e.g., "42" -> 42). Default True.
            - Sources should use True (normalize external data)
            - Transforms/Sinks should use False (wrong types = upstream bug)

    Returns:
        A PluginSchema subclass with the specified fields and validation

    The generated schema:
    - Dynamic mode: extra="allow", accepts any fields (no type checking)
    - Strict mode: extra="forbid", rejects unknown fields
    - Free mode: extra="allow", requires specified fields, allows extras

    Examples:
        # Source - coerces external data
        source_schema = create_schema_from_config(config, "CSVRow", allow_coercion=True)

        # Transform - expects clean data from upstream
        transform_schema = create_schema_from_config(config, "Input", allow_coercion=False)
    """
    if config.is_dynamic:
        # Dynamic schema - accept anything (no type validation either way)
        return _create_dynamic_schema(name)

    # Explicit schema - strict or free mode
    return _create_explicit_schema(config, name, allow_coercion)


def _create_dynamic_schema(name: str) -> type[PluginSchema]:
    """Create a schema that accepts any fields.

    Note: Dynamic schemas don't do type checking, so coercion is irrelevant.
    """
    return create_model(
        name,
        __base__=PluginSchema,
        __module__=__name__,
        __config__=ConfigDict(
            extra="allow",
            # No strict setting needed - no fields to validate types against
        ),
    )


def _create_explicit_schema(
    config: SchemaConfig,
    name: str,
    allow_coercion: bool,
) -> type[PluginSchema]:
    """Create a schema with explicit field definitions."""
    assert config.fields is not None
    assert config.mode is not None

    # Build field definitions for create_model
    # Format: field_name=(type, default) or field_name=(type, ...)
    field_definitions: dict[str, Any] = {}

    for field_def in config.fields:
        python_type = _get_python_type(field_def)

        if field_def.required:
            # Required field - use ... (Ellipsis) as default
            field_definitions[field_def.name] = (python_type, ...)
        else:
            # Optional field - default to None
            field_definitions[field_def.name] = (python_type, None)

    # Determine extra field handling
    extra_mode = "allow" if config.mode == "free" else "forbid"

    # Coercion control: strict=True means NO coercion (Pydantic's semantics)
    # allow_coercion=True  -> strict=False (coerce)
    # allow_coercion=False -> strict=True  (reject wrong types)
    use_strict = not allow_coercion

    return create_model(
        name,
        __base__=PluginSchema,
        __module__=__name__,
        __config__=ConfigDict(
            extra=extra_mode,
            strict=use_strict,
        ),
        **field_definitions,
    )


def _get_python_type(field_def: FieldDefinition) -> type:
    """Convert field definition to Python type annotation.

    For optional fields, returns the base type (not Optional).
    Pydantic handles None via the default value.
    """
    base_type = TYPE_MAP[field_def.field_type]

    if field_def.required:
        return base_type
    else:
        # Optional: allow None
        return base_type | None
```

**Step 4: Run tests to verify they pass**

Run: `pytest tests/plugins/test_schema_factory.py -v`

Expected: All 24 tests pass (16 original + 7 coercion control + 1 compliance)

**Step 5: Commit**

```bash
git add src/elspeth/plugins/schema_factory.py tests/plugins/test_schema_factory.py
git commit -m "$(cat <<'EOF'
feat(plugins): add schema factory for config-driven schemas

Creates Pydantic models at runtime from SchemaConfig:
- Dynamic: accepts any fields (extra="allow")
- Strict: accepts exactly specified fields (extra="forbid")
- Free: requires specified fields, allows extras (extra="allow")

Type coercion enabled (strict=False) for source boundary validation.
Supports: str, int, float, bool, any types with ? suffix for optional.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 3: Add Schema to Plugin Config Base

**Files:**
- Modify: `src/elspeth/plugins/config_base.py`
- Test: `tests/plugins/test_config_base.py`

**Step 1: Read current config_base.py**

Review lines 1-80 of `src/elspeth/plugins/config_base.py` to understand current structure.

**Step 2: Write failing tests**

Add to existing `tests/plugins/test_config_base.py` or create if needed:

```python
"""Tests for plugin config base classes with schema support."""

import pytest


class TestPluginConfigWithSchema:
    """Tests for schema in plugin config."""

    def test_plugin_config_accepts_schema(self) -> None:
        """PluginConfig can have schema section."""
        from elspeth.plugins.config_base import PluginConfig

        class TestConfig(PluginConfig):
            name: str

        config = TestConfig.from_dict({
            "name": "test",
            "schema": {"fields": "dynamic"},
        })
        assert config.name == "test"
        assert config.schema_config is not None
        assert config.schema_config.is_dynamic is True

    def test_plugin_config_schema_optional_by_default(self) -> None:
        """Schema is optional in base PluginConfig."""
        from elspeth.plugins.config_base import PluginConfig

        class TestConfig(PluginConfig):
            name: str

        config = TestConfig.from_dict({"name": "test"})
        assert config.name == "test"
        assert config.schema_config is None

    def test_data_plugin_config_requires_schema(self) -> None:
        """DataPluginConfig (for sources/sinks) requires schema."""
        from elspeth.plugins.config_base import DataPluginConfig

        class SourceConfig(DataPluginConfig):
            path: str

        # Should fail without schema
        with pytest.raises(ValueError, match="schema.*required"):
            SourceConfig.from_dict({"path": "data.csv"})

        # Should succeed with schema
        config = SourceConfig.from_dict({
            "path": "data.csv",
            "schema": {"fields": "dynamic"},
        })
        assert config.schema_config is not None

    def test_data_plugin_config_with_explicit_schema(self) -> None:
        """DataPluginConfig accepts explicit schema definition."""
        from elspeth.plugins.config_base import DataPluginConfig

        class SourceConfig(DataPluginConfig):
            path: str

        config = SourceConfig.from_dict({
            "path": "data.csv",
            "schema": {
                "mode": "strict",
                "fields": ["id: int", "name: str"],
            },
        })
        assert config.schema_config.mode == "strict"
        assert len(config.schema_config.fields) == 2
```

**Step 3: Run tests to verify they fail**

Run: `pytest tests/plugins/test_config_base.py::TestPluginConfigWithSchema -v`

Expected: FAIL

**Step 4: Implement schema support in config base**

Modify `src/elspeth/plugins/config_base.py`:

```python
"""Plugin configuration base classes.

This module provides base classes for typed plugin configurations.
All plugin configs inherit from PluginConfig (optional schema) or
DataPluginConfig (required schema for data-processing plugins).
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Self

from pydantic import BaseModel, ConfigDict, model_validator

from elspeth.contracts.schema import SchemaConfig
from elspeth.plugins.errors import PluginConfigError


class PluginConfig(BaseModel):
    """Base configuration for all plugins.

    Provides:
    - Strict validation (rejects unknown fields)
    - Immutability after creation
    - Optional schema configuration

    Subclasses define their specific config fields.
    """

    model_config = ConfigDict(
        extra="forbid",  # Reject unknown fields (strict system config)
        frozen=True,     # Immutable after creation
    )

    # Schema config is optional in base class
    # Subclasses requiring data validation should use DataPluginConfig
    schema_config: SchemaConfig | None = None

    @classmethod
    def from_dict(cls, config: dict[str, Any]) -> Self:
        """Create config from dictionary with clear error messages.

        Args:
            config: Configuration dictionary

        Returns:
            Validated config instance

        Raises:
            PluginConfigError: If validation fails
        """
        try:
            # Extract and parse schema if present
            config_copy = dict(config)
            if "schema" in config_copy:
                schema_dict = config_copy.pop("schema")
                config_copy["schema_config"] = SchemaConfig.from_dict(schema_dict)

            return cls.model_validate(config_copy)
        except Exception as e:
            raise PluginConfigError(
                f"Invalid configuration for {cls.__name__}: {e}"
            ) from e


class DataPluginConfig(PluginConfig):
    """Configuration for data-processing plugins (sources, sinks, transforms).

    Requires schema configuration - either 'fields: dynamic' or explicit
    field definitions with mode (strict/free).

    This ensures all data-processing plugins have auditable schema choices.
    """

    @model_validator(mode="after")
    def _require_schema(self) -> Self:
        """Ensure schema is provided for data plugins."""
        if self.schema_config is None:
            raise ValueError(
                "Data plugins require 'schema' configuration. "
                "Use 'schema: {fields: dynamic}' to accept any fields, or "
                "provide explicit field definitions with mode (strict/free)."
            )
        return self


class PathConfig(DataPluginConfig):
    """Configuration for file-based data plugins.

    Requires:
    - path: Path to the data file
    - schema: Schema configuration (inherited from DataPluginConfig)
    """

    path: str

    @model_validator(mode="after")
    def _validate_path(self) -> Self:
        """Ensure path is non-empty."""
        if not self.path or not self.path.strip():
            raise ValueError("path cannot be empty")
        return self

    def resolved_path(self, base_dir: Path | None = None) -> Path:
        """Resolve path relative to base directory.

        Args:
            base_dir: Base directory for relative paths (default: cwd)

        Returns:
            Resolved absolute path
        """
        path = Path(self.path)
        if path.is_absolute():
            return path
        base = base_dir or Path.cwd()
        return base / path
```

**Step 5: Run tests to verify they pass**

Run: `pytest tests/plugins/test_config_base.py -v`

Expected: All tests pass

**Step 6: Commit**

```bash
git add src/elspeth/plugins/config_base.py tests/plugins/test_config_base.py
git commit -m "$(cat <<'EOF'
feat(plugins): add schema support to plugin config base classes

- PluginConfig: Optional schema_config field
- DataPluginConfig: Requires schema (for sources/sinks/transforms)
- PathConfig: Inherits schema requirement for file-based plugins

Schema is mandatory for data-processing plugins to ensure auditable
schema choices. Use 'fields: dynamic' or explicit field definitions.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 4: Add Schema Recording to Landscape

**Files:**
- Modify: `src/elspeth/core/landscape/recorder.py`
- Test: `tests/core/landscape/test_recorder.py`

**Step 1: Review current register_node signature**

Check `recorder.py` lines 420-500 to understand current `register_node()` signature.

**Step 2: Write failing tests**

Add to `tests/core/landscape/test_recorder.py`:

```python
class TestSchemaRecording:
    """Tests for schema configuration recording in audit trail."""

    def test_register_node_with_dynamic_schema(
        self, recorder: LandscapeRecorder, run_id: str
    ) -> None:
        """Dynamic schema recorded in node registration."""
        from elspeth.contracts.schema import SchemaConfig

        schema_config = SchemaConfig.from_dict({"fields": "dynamic"})

        node_id = recorder.register_node(
            run_id=run_id,
            plugin_name="csv_source",
            node_type="source",
            plugin_version="1.0.0",
            config={"path": "data.csv"},
            schema_config=schema_config,
        )

        node = recorder.get_node(node_id)
        assert node is not None
        assert node.schema_mode == "dynamic"
        assert node.schema_fields is None

    def test_register_node_with_explicit_schema(
        self, recorder: LandscapeRecorder, run_id: str
    ) -> None:
        """Explicit schema fields recorded in node registration."""
        from elspeth.contracts.schema import SchemaConfig

        schema_config = SchemaConfig.from_dict({
            "mode": "strict",
            "fields": ["id: int", "name: str"],
        })

        node_id = recorder.register_node(
            run_id=run_id,
            plugin_name="csv_source",
            node_type="source",
            plugin_version="1.0.0",
            config={"path": "data.csv"},
            schema_config=schema_config,
        )

        node = recorder.get_node(node_id)
        assert node is not None
        assert node.schema_mode == "strict"
        assert node.schema_fields is not None
        assert len(node.schema_fields) == 2
        assert node.schema_fields[0]["name"] == "id"
        assert node.schema_fields[1]["name"] == "name"

```

**Step 3: Run tests to verify they fail**

Run: `pytest tests/core/landscape/test_recorder.py::TestSchemaRecording -v`

Expected: FAIL (no schema_config parameter)

**Step 4: Add schema recording to landscape**

This requires:
1. Add `schema_mode` and `schema_fields_json` columns to `nodes_table` in schema.py
2. Add `schema_mode` and `schema_fields` fields to `Node` dataclass in audit.py
3. Update `register_node()` to accept and store schema_config
4. Update `_row_to_node()` to read schema fields

**Step 4a: Update schema.py (add columns)**

Add to `nodes_table` definition:

```python
Column("schema_mode", String(16)),  # "dynamic", "strict", "free", or NULL
Column("schema_fields_json", Text),  # JSON array of field definitions, or NULL
```

**Step 4b: Update audit.py (add fields to Node dataclass)**

```python
@dataclass
class Node:
    # ... existing fields ...
    schema_mode: str | None = None  # "dynamic", "strict", "free"
    schema_fields: list[dict] | None = None  # Field definitions if explicit
```

**Step 4c: Update recorder.py register_node()**

```python
def register_node(
    self,
    run_id: str,
    plugin_name: str,
    node_type: str,
    plugin_version: str,
    config: dict[str, Any],
    schema_config: SchemaConfig,  # REQUIRED - no nodes without schemas
    node_id: str | None = None,
    sequence: int | None = None,
    schema_hash: str | None = None,
    determinism: Determinism = Determinism.DETERMINISTIC,
) -> str:
    """Register a plugin node in the execution graph.

    Args:
        ...existing args...
        schema_config: Schema configuration for audit trail (REQUIRED)
    """
    # ... existing code ...

    # Extract schema info for audit (schema_config is REQUIRED)
    if schema_config.is_dynamic:
        schema_mode = "dynamic"
        schema_fields_json = None
    else:
        schema_mode = schema_config.mode
        schema_fields_json = canonical_json(
            [f.to_dict() for f in schema_config.fields]
        )

    # Insert with schema columns (SQLAlchemy 2.0 pattern)
    with self._engine.begin() as conn:
        conn.execute(
            nodes_table.insert().values(
                # ... existing values ...
                schema_mode=schema_mode,
                schema_fields_json=schema_fields_json,
            )
        )
```

**Step 5: Run tests to verify they pass**

Run: `pytest tests/core/landscape/test_recorder.py::TestSchemaRecording -v`

Expected: All tests pass

**Step 6: Commit**

```bash
git add src/elspeth/core/landscape/schema.py \
        src/elspeth/contracts/audit.py \
        src/elspeth/core/landscape/recorder.py \
        tests/core/landscape/test_recorder.py
git commit -m "$(cat <<'EOF'
feat(landscape): record schema configuration in audit trail

Adds schema_mode and schema_fields columns to nodes table for audit:
- schema_mode: "dynamic", "strict", or "free"
- schema_fields: JSON array of field definitions (if explicit)

Auditors can now query: "What schema validation was configured for
each plugin in this pipeline run?"

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 4.5: Add Validation Error Recording to PluginContext

**Files:**
- Modify: `src/elspeth/plugins/context.py`
- Modify: `src/elspeth/core/landscape/recorder.py` (add record_validation_error)
- Test: `tests/plugins/test_context.py`

**Goal:** Sources need a way to record validation errors that get captured in the audit trail. This enables quarantining invalid rows while maintaining complete audit coverage.

**Step 1: Write failing tests for validation error recording**

Add to `tests/plugins/test_context.py`:

```python
"""Tests for PluginContext validation error recording."""

import pytest


class TestValidationErrorRecording:
    """Tests for recording validation errors from sources."""

    def test_record_validation_error_exists(self) -> None:
        """PluginContext has record_validation_error method."""
        from elspeth.plugins.context import PluginContext

        ctx = PluginContext(run_id="test-run", config={})
        assert hasattr(ctx, "record_validation_error")
        assert callable(ctx.record_validation_error)

    def test_record_validation_error_without_landscape(self) -> None:
        """record_validation_error works without landscape (logs warning)."""
        from elspeth.plugins.context import PluginContext

        ctx = PluginContext(run_id="test-run", config={})

        # Should not raise - just logs warning
        ctx.record_validation_error(
            row={"id": 1, "bad_field": "invalid"},
            error="Field 'count' expected int, got str",
            schema_mode="strict",
        )

    def test_record_validation_error_with_landscape(
        self, recorder: "LandscapeRecorder", run_id: str
    ) -> None:
        """record_validation_error writes to landscape audit trail."""
        from elspeth.plugins.context import PluginContext

        ctx = PluginContext(
            run_id=run_id,
            config={},
            landscape=recorder,
            node_id="csv_source_node",
            plugin_name="csv",
        )

        ctx.record_validation_error(
            row={"id": 1, "count": "not_a_number"},
            error="Field 'count' expected int, got str",
            schema_mode="strict",
        )

        # Verify recorded in landscape
        errors = recorder.get_validation_errors(run_id=run_id)
        assert len(errors) == 1
        assert errors[0].node_id == "csv_source_node"
        assert "count" in errors[0].error
        assert errors[0].schema_mode == "strict"

    def test_record_validation_error_returns_quarantine_token(self) -> None:
        """record_validation_error returns token for tracking quarantined row."""
        from elspeth.plugins.context import PluginContext

        ctx = PluginContext(run_id="test-run", config={}, node_id="source_node")

        token = ctx.record_validation_error(
            row={"id": 42, "invalid": "data"},
            error="validation failed",
            schema_mode="strict",
        )

        assert token is not None
        assert token.row_id is not None  # Generated or extracted from row
        assert token.node_id == "source_node"
```

**Step 2: Implement record_validation_error in PluginContext**

Update `src/elspeth/plugins/context.py`:

```python
@dataclass
class ValidationErrorToken:
    """Token returned when recording a validation error.

    Allows tracking the quarantined row through the audit trail.
    """

    row_id: str
    node_id: str
    error_id: str | None = None  # Set if recorded to landscape


@dataclass
class PluginContext:
    # ... existing fields ...

    def record_validation_error(
        self,
        row: dict[str, Any],
        error: str,
        schema_mode: str,
    ) -> ValidationErrorToken:
        """Record a validation error for audit trail.

        Called by sources when row validation fails. The row will be
        quarantined (not processed further) but the error is recorded
        for complete audit coverage.

        Args:
            row: The row data that failed validation
            error: Description of the validation failure
            schema_mode: "strict", "free", or "dynamic"

        Returns:
            ValidationErrorToken for tracking the quarantined row
        """
        import logging
        from elspeth.core.canonical import stable_hash

        logger = logging.getLogger(__name__)

        # Generate row_id from content hash if not present
        row_id = str(row.get("id", stable_hash(row)[:16]))

        if self.landscape is None:
            logger.warning(
                "Validation error not recorded (no landscape): %s",
                error,
            )
            return ValidationErrorToken(
                row_id=row_id,
                node_id=self.node_id or "unknown",
            )

        # Record to landscape audit trail
        error_id = self.landscape.record_validation_error(
            run_id=self.run_id,
            node_id=self.node_id,
            row_data=row,
            error=error,
            schema_mode=schema_mode,
        )

        return ValidationErrorToken(
            row_id=row_id,
            node_id=self.node_id or "unknown",
            error_id=error_id,
        )
```

**Step 3: Add landscape support for validation errors**

Add to `src/elspeth/core/landscape/recorder.py`:

```python
def record_validation_error(
    self,
    run_id: str,
    node_id: str | None,
    row_data: dict[str, Any],
    error: str,
    schema_mode: str,
) -> str:
    """Record a validation error in the audit trail.

    Args:
        run_id: Current run ID
        node_id: Node where validation failed
        row_data: The row that failed validation
        error: Error description
        schema_mode: Schema mode that caught the error

    Returns:
        error_id for tracking
    """
    from elspeth.core.canonical import canonical_json, stable_hash

    error_id = f"verr_{uuid4().hex[:12]}"

    with self._engine.begin() as conn:
        conn.execute(
            validation_errors_table.insert().values(
                error_id=error_id,
                run_id=run_id,
                node_id=node_id,
                row_hash=stable_hash(row_data),
                row_data_json=canonical_json(row_data),
                error=error,
                schema_mode=schema_mode,
                created_at=datetime.utcnow(),
            )
        )

    return error_id


def get_validation_errors(self, run_id: str) -> list[ValidationError]:
    """Get all validation errors for a run."""
    with self._engine.connect() as conn:
        result = conn.execute(
            validation_errors_table.select().where(
                validation_errors_table.c.run_id == run_id
            )
        )
        return [self._row_to_validation_error(row) for row in result]
```

**Step 4: Add validation_errors table to schema**

Add to `src/elspeth/core/landscape/schema.py`:

```python
validation_errors_table = Table(
    "validation_errors",
    metadata,
    Column("error_id", String(32), primary_key=True),
    Column("run_id", String(64), ForeignKey("runs.run_id"), nullable=False),
    Column("node_id", String(64)),
    Column("row_hash", String(64), nullable=False),
    Column("row_data_json", Text),  # Store the row for debugging
    Column("error", Text, nullable=False),
    Column("schema_mode", String(16), nullable=False),
    Column("created_at", DateTime, nullable=False),
)
```

**Step 5: Run tests**

Run: `pytest tests/plugins/test_context.py::TestValidationErrorRecording -v`

Expected: All tests pass

**Step 6: Commit**

```bash
git add src/elspeth/plugins/context.py \
        src/elspeth/core/landscape/recorder.py \
        src/elspeth/core/landscape/schema.py \
        tests/plugins/test_context.py
git commit -m "$(cat <<'EOF'
feat(context): add record_validation_error for source validation

Sources can now record validation errors to the audit trail:
- ValidationErrorToken returned for tracking quarantined rows
- Errors recorded with row hash, data, and schema mode
- Works gracefully without landscape (logs warning)

Enables complete audit coverage even for rejected rows.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 5: Update Source Plugins

**Files:**
- Modify: `src/elspeth/plugins/sources/csv_source.py`
- Modify: `src/elspeth/plugins/sources/json_source.py`
- Test: existing source tests

**Goal:** Remove hardcoded schema classes, use config-driven schemas with validation at load boundary. Sources use `allow_coercion=True` to normalize external data.

**Step 1: Update CSVSource**

In `src/elspeth/plugins/sources/csv_source.py`:

```python
"""CSV source plugin with config-driven schema.

IMPORTANT: Sources use allow_coercion=True to normalize external data.
This is the ONLY place in the pipeline where coercion is allowed.
"""

from __future__ import annotations

from pathlib import Path
from typing import TYPE_CHECKING, Any, Iterator

import pandas as pd

from elspeth.contracts import PluginSchema
from elspeth.plugins.base import BaseSource
from elspeth.plugins.config_base import PathConfig
from elspeth.plugins.schema_factory import create_schema_from_config

if TYPE_CHECKING:
    from elspeth.plugins.context import PluginContext


class CSVSourceConfig(PathConfig):
    """Configuration for CSV source plugin."""

    delimiter: str = ","
    encoding: str = "utf-8"
    skip_rows: int = 0


class CSVSource(BaseSource):
    """Load data from CSV files with config-driven schema validation.

    Schema is specified in config:
    - schema: {fields: dynamic} - Accept any columns
    - schema: {mode: strict, fields: [...]} - Validate exact columns
    - schema: {mode: free, fields: [...]} - Validate required columns, allow extras

    Per three-tier trust model:
    - External data (CSV) is "Their Data" - zero trust
    - Coercion is ALLOWED here (e.g., "42" -> 42)
    - Invalid rows are quarantined, not crashed
    """

    name = "csv"

    def __init__(self, config: dict[str, Any]) -> None:
        """Initialize CSV source.

        Args:
            config: Must include 'path' and 'schema' keys
        """
        super().__init__(config)
        cfg = CSVSourceConfig.from_dict(config)

        self._path = cfg.resolved_path()
        self._delimiter = cfg.delimiter
        self._encoding = cfg.encoding
        self._skip_rows = cfg.skip_rows
        self._schema_config = cfg.schema_config

        # Create schema class from config
        # CRITICAL: allow_coercion=True for sources (external data boundary)
        self._schema_class = create_schema_from_config(
            cfg.schema_config,
            "CSVRowSchema",
            allow_coercion=True,  # Sources normalize external data
        )

        # Store for base class
        self.output_schema = self._schema_class

    def load(self, ctx: PluginContext) -> Iterator[dict[str, Any]]:
        """Load and validate rows from CSV file.

        Yields:
            Validated row dictionaries (coerced to correct types)

        Note:
            Validation errors are recorded but don't stop processing.
            Invalid rows are quarantined (via ctx) and skipped.
        """
        df = pd.read_csv(
            self._path,
            delimiter=self._delimiter,
            encoding=self._encoding,
            skiprows=self._skip_rows,
        )

        for record in df.to_dict(orient="records"):
            # Normalize keys to strings
            row = {str(k): v for k, v in record.items()}

            # Validate and coerce through schema
            try:
                validated = self._schema_class.model_validate(row)
                yield validated.to_row()
            except Exception as e:
                # Record validation failure - row quarantined
                ctx.record_validation_error(
                    row=row,
                    error=str(e),
                    schema_mode=self._schema_config.mode or "dynamic",
                )
                # Skip invalid row - don't yield
                continue

    def close(self) -> None:
        """Clean up resources."""
        pass


# Remove old CSVOutputSchema class - no longer needed
```

**Step 2: Update JSONSource similarly**

Apply same pattern to `json_source.py`.

**Step 3: Update existing tests**

Update tests to provide schema config:

```python
# Old:
source = CSVSource({"path": "data.csv"})

# New:
source = CSVSource({
    "path": "data.csv",
    "schema": {"fields": "dynamic"},
})
```

**Step 4: Run source tests**

Run: `pytest tests/plugins/sources/ -v`

Expected: All tests pass

**Step 5: Commit**

```bash
git add src/elspeth/plugins/sources/*.py tests/plugins/sources/
git commit -m "$(cat <<'EOF'
refactor(sources): use config-driven schemas with validation

CSV and JSON sources now:
- Require 'schema' in config (dynamic or explicit)
- Validate rows at load boundary
- Coerce types per schema definition
- Record validation errors for quarantine

Removes CSVOutputSchema and JSONOutputSchema hardcoded classes.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 6: Update Sink Plugins

**Files:**
- Modify: `src/elspeth/plugins/sinks/csv_sink.py`
- Modify: `src/elspeth/plugins/sinks/json_sink.py`
- Modify: `src/elspeth/plugins/sinks/database_sink.py`

**Goal:** Remove hardcoded schemas. Sinks use `allow_coercion=False` to enforce that transforms output correct types. If a transform sends wrong types, it's a bug that should crash.

**Design Note: Sink Validation Behavior**

Per the three-tier trust model, sinks receive "pipeline data" (elevated trust):
- Types should be correct (source validated/coerced them)
- If types are wrong, that's an upstream bug → **crash** (not silently coerce)
- This surfaces bugs immediately rather than letting bad data reach the audit trail

The schema is used for:
1. **Audit documentation** - recorded in landscape
2. **Runtime validation** - crashes on type violations (optional, controlled by config)

**Step 1: Update CSVSink**

```python
"""CSV sink plugin with config-driven schema.

IMPORTANT: Sinks use allow_coercion=False to enforce that transforms
output correct types. Wrong types = upstream bug = crash.
"""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from elspeth.plugins.base import BaseSink
from elspeth.plugins.config_base import PathConfig
from elspeth.plugins.schema_factory import create_schema_from_config

if TYPE_CHECKING:
    from elspeth.plugins.context import PluginContext


class CSVSinkConfig(PathConfig):
    """Configuration for CSV sink plugin."""

    validate_input: bool = True  # Validate incoming rows against schema


class CSVSink(BaseSink):
    """Write data to CSV files with schema enforcement.

    Schema is specified in config:
    - schema: {fields: dynamic} - Accept any columns (no validation)
    - schema: {mode: strict, fields: [...]} - Validate exact columns
    - schema: {mode: free, fields: [...]} - Validate required columns, allow extras

    Per three-tier trust model:
    - Pipeline data should already be validated by source
    - Coercion is FORBIDDEN here (wrong types = upstream bug)
    - Type violations CRASH to surface bugs immediately
    """

    name = "csv"

    def __init__(self, config: dict[str, Any]) -> None:
        super().__init__(config)
        cfg = CSVSinkConfig.from_dict(config)

        self._path = cfg.resolved_path()
        self._schema_config = cfg.schema_config
        self._validate_input = cfg.validate_input

        # Create schema for validation
        # CRITICAL: allow_coercion=False - wrong types are bugs, not data to fix
        self._schema_class = create_schema_from_config(
            cfg.schema_config,
            "CSVRowSchema",
            allow_coercion=False,  # Sinks reject wrong types (upstream bug)
        )
        self.input_schema = self._schema_class

        # ... rest of init ...

    def write(self, rows: list[dict[str, Any]], ctx: PluginContext) -> ArtifactDescriptor:
        """Write rows to CSV file.

        Args:
            rows: Rows to write (expected to match schema)
            ctx: Plugin context

        Returns:
            Artifact descriptor for audit trail

        Raises:
            ValidationError: If any row violates schema (upstream bug)
        """
        if self._validate_input and not self._schema_config.is_dynamic:
            # Validate each row - crash on violation (this is a bug!)
            for row in rows:
                self._schema_class.model_validate(row)  # Raises on failure

        # ... actual write logic ...
```

**Step 2: Update JSONSink and DatabaseSink similarly**

**Step 3: Update existing tests**

Add schema config to test fixtures.

**Step 4: Run sink tests**

Run: `pytest tests/plugins/sinks/ -v`

Expected: All tests pass

**Step 5: Commit**

```bash
git add src/elspeth/plugins/sinks/*.py tests/plugins/sinks/
git commit -m "$(cat <<'EOF'
refactor(sinks): use config-driven schemas for audit documentation

CSV, JSON, and Database sinks now:
- Require 'schema' in config (for audit trail)
- Document expected input format
- Trust transforms to provide valid data (by contract)

Removes CSVInputSchema, JSONInputSchema, DatabaseInputSchema.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 7: Update Transform Plugins

**Files:**
- Modify: `src/elspeth/plugins/transforms/field_mapper.py`
- Modify: `src/elspeth/plugins/transforms/passthrough.py`

**Goal:** Remove hardcoded schemas. Transforms use `allow_coercion=False` for input validation (upstream bugs crash) and document output schema for downstream.

**Design Note: Transform Validation**

Transforms sit between source and sink:
- **Input validation**: `allow_coercion=False` - wrong types from source = bug
- **Output validation**: Optional - transforms should be tested to ensure correct output

**Step 1: Update FieldMapper**

```python
"""Field mapper transform with config-driven schemas.

IMPORTANT: Transforms use allow_coercion=False to catch upstream bugs.
If the source outputs wrong types, the transform crashes immediately.
"""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

from elspeth.plugins.base import BaseTransform
from elspeth.plugins.config_base import DataPluginConfig
from elspeth.plugins.schema_factory import create_schema_from_config
from elspeth.plugins.results import TransformResult

if TYPE_CHECKING:
    from elspeth.plugins.context import PluginContext


class FieldMapperConfig(DataPluginConfig):
    """Configuration for field mapper transform."""

    mappings: dict[str, str]  # output_field -> source_path
    validate_input: bool = True  # Validate incoming rows against schema


class FieldMapper(BaseTransform):
    """Map fields from input rows to output rows.

    Schema config specifies expected input structure.
    Output schema derived from mappings.

    Per three-tier trust model:
    - Receives "pipeline data" (elevated trust)
    - Coercion FORBIDDEN - wrong types = source bug
    - Type violations CRASH to surface bugs
    """

    name = "field_mapper"

    def __init__(self, config: dict[str, Any]) -> None:
        super().__init__(config)
        cfg = FieldMapperConfig.from_dict(config)

        self._mappings = cfg.mappings
        self._schema_config = cfg.schema_config
        self._validate_input = cfg.validate_input

        # Input schema from config
        # CRITICAL: allow_coercion=False - wrong types are source bugs
        self._input_schema = create_schema_from_config(
            cfg.schema_config,
            "FieldMapperInput",
            allow_coercion=False,  # Transforms reject wrong types
        )
        self.input_schema = self._input_schema

        # Output schema: dynamic (fields determined by mapping)
        # Could derive from mappings in future
        self.output_schema = self._input_schema  # Simplified for now

    def process(self, row: dict[str, Any], ctx: PluginContext) -> TransformResult:
        """Process a row, mapping fields per configuration.

        Args:
            row: Input row (expected to match input_schema)
            ctx: Plugin context

        Returns:
            TransformResult with mapped fields

        Raises:
            ValidationError: If row violates schema (upstream bug)
        """
        # Validate input - crash on wrong types (source bug!)
        if self._validate_input and not self._schema_config.is_dynamic:
            self._input_schema.model_validate(row)  # Raises on failure

        # ... field mapping logic ...
        # (wrap operations on row VALUES in try/except for their-data errors)
```

**Step 2: Update Passthrough similarly**

**Step 3: Update tests**

**Step 4: Run transform tests**

Run: `pytest tests/plugins/transforms/ -v`

Expected: All tests pass

**Step 5: Commit**

```bash
git add src/elspeth/plugins/transforms/*.py tests/plugins/transforms/
git commit -m "$(cat <<'EOF'
refactor(transforms): use config-driven schemas

FieldMapper and Passthrough transforms now:
- Require 'schema' in config
- Document input/output expectations
- Schema recorded in audit trail

Removes FieldMapperSchema, PassThroughSchema.

Part of WP-11.99: Config-Driven Plugin Schemas

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 8: Update WP-12 Plan (Simplified)

**Files:**
- Modify: `docs/plans/2026-01-17-wp12-utility-consolidation.md`

**Step 1: Simplify WP-12**

WP-12 no longer needs DynamicSchema consolidation. Update to only include:
- Extract `get_nested_field()` to `utils.py`
- Update `field_mapper.py` to use shared utility

**Step 2: Commit**

```bash
git add docs/plans/2026-01-17-wp12-utility-consolidation.md
git commit -m "$(cat <<'EOF'
docs(plans): simplify WP-12 after WP-11.99 schema refactor

WP-11.99 handles schema consolidation properly via config-driven
schemas. WP-12 now only extracts get_nested_field() utility.

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 9: Final Verification

**Step 1: Run mypy on all modified files**

```bash
mypy src/elspeth/contracts/schema.py \
     src/elspeth/plugins/schema_factory.py \
     src/elspeth/plugins/config_base.py \
     src/elspeth/plugins/sources/*.py \
     src/elspeth/plugins/sinks/*.py \
     src/elspeth/plugins/transforms/*.py \
     --strict
```

Expected: No errors

**Step 2: Run all plugin tests**

```bash
pytest tests/plugins/ -v
```

Expected: All tests pass

**Step 3: Run landscape tests**

```bash
pytest tests/core/landscape/ -v
```

Expected: All tests pass

**Step 4: Verify no hardcoded dynamic schemas remain**

```bash
grep -r "extra.*=.*allow" src/elspeth/plugins/ --include="*.py" | grep -v schema_factory
```

Expected: No results (only schema_factory should have extra="allow")

**Step 5: Final commit**

```bash
git add -A
git commit -m "$(cat <<'EOF'
chore: verify WP-11.99 complete - config-driven schemas implemented

Verification:
- SchemaConfig and FieldDefinition types in contracts/schema.py
- Schema factory creates Pydantic models from config
- All 7 plugins use config-driven schemas
- Schema choices recorded in audit trail (landscape)
- Type coercion at source boundary
- No hardcoded extra="allow" schemas remain
- All tests pass
- mypy clean

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Verification Checklist

### Core Implementation
- [ ] `SchemaConfig` and `FieldDefinition` in `contracts/schema.py`
- [ ] `create_schema_from_config()` with `allow_coercion` parameter in `plugins/schema_factory.py`
- [ ] `DataPluginConfig` requires schema
- [ ] `ValidationErrorToken` and `record_validation_error()` in `plugins/context.py`
- [ ] `validation_errors` table in landscape schema

### Trust Model Enforcement
- [ ] Sources use `allow_coercion=True` (normalize external data)
- [ ] Transforms use `allow_coercion=False` (wrong types = source bug)
- [ ] Sinks use `allow_coercion=False` (wrong types = transform bug)
- [ ] Tests verify coercion rejection in transforms/sinks

### Audit Trail
- [ ] Landscape records `schema_mode` and `schema_fields`
- [ ] Validation errors recorded with row hash and data
- [ ] Schema configuration recorded at node registration

### Cleanup
- [ ] No `CSVOutputSchema`, `JSONOutputSchema`, etc. remain
- [ ] No hardcoded `extra="allow"` schemas in plugin files
- [ ] All tests pass
- [ ] mypy --strict passes

---

## Files Changed Summary

| File | Change Type | Description |
|------|-------------|-------------|
| `src/elspeth/contracts/schema.py` | CREATE | SchemaConfig, FieldDefinition types |
| `src/elspeth/plugins/schema_factory.py` | CREATE | Dynamic Pydantic model creation with `allow_coercion` |
| `src/elspeth/plugins/config_base.py` | MODIFY | Add DataPluginConfig with required schema |
| `src/elspeth/plugins/context.py` | MODIFY | Add ValidationErrorToken, record_validation_error() |
| `src/elspeth/core/landscape/schema.py` | MODIFY | Add schema_mode, schema_fields, validation_errors table |
| `src/elspeth/contracts/audit.py` | MODIFY | Add schema fields to Node dataclass |
| `src/elspeth/core/landscape/recorder.py` | MODIFY | Record schema config, add record_validation_error() |
| `src/elspeth/plugins/sources/csv_source.py` | MODIFY | Config-driven schema with `allow_coercion=True` |
| `src/elspeth/plugins/sources/json_source.py` | MODIFY | Config-driven schema with `allow_coercion=True` |
| `src/elspeth/plugins/sinks/csv_sink.py` | MODIFY | Config-driven schema with `allow_coercion=False` |
| `src/elspeth/plugins/sinks/json_sink.py` | MODIFY | Config-driven schema with `allow_coercion=False` |
| `src/elspeth/plugins/sinks/database_sink.py` | MODIFY | Config-driven schema with `allow_coercion=False` |
| `src/elspeth/plugins/transforms/field_mapper.py` | MODIFY | Config-driven schema with `allow_coercion=False` |
| `src/elspeth/plugins/transforms/passthrough.py` | MODIFY | Config-driven schema with `allow_coercion=False` |
| `tests/contracts/test_schema_config.py` | CREATE | SchemaConfig tests (15 tests) |
| `tests/plugins/test_schema_factory.py` | CREATE | Schema factory + coercion control tests (24 tests) |
| `tests/plugins/test_context.py` | MODIFY | ValidationErrorToken tests (4 tests) |
| Various test files | MODIFY | Add schema config to fixtures |

---

## Dependency Notes

- **Depends on:** Nothing
- **Unlocks:** WP-12 (simplified)
- **Risk:** Medium - touches config system and all data-processing plugins
- **Estimated Effort:** 4-6 hours

---

## Rollback Trigger

If schema validation breaks existing pipeline behavior:
1. Make `schema` optional in `DataPluginConfig` (revert to `PluginConfig`)
2. Add default dynamic schema when not specified
3. Assess which plugins need mandatory vs optional schema

The goal is auditable schema choices, not breaking existing configs.
