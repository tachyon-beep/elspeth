# WP-11.99a: Quarantine Sink Configuration

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:subagent-driven-development to implement this plan task-by-task.

**Goal:** Add required configuration for source plugins to specify where non-conformant rows are sent.

**Architecture:** Extend source configuration to require explicit `on_validation_failure` destination - no silent drops, no hidden defaults. Builds on existing `record_validation_error()` infrastructure from WP-11.99.

**Tech Stack:** Python 3.12, Pydantic, typing

---

## Key Architectural Decisions

| Decision | Rationale |
|----------|-----------|
| `on_validation_failure` is REQUIRED | No hidden behavior - operator must explicitly acknowledge what happens to bad data |
| `"discard"` for explicit /dev/null | Searchable in configs, clearly intentional, not a missing value |
| Extend existing `record_validation_error` | WP-11.99 already records errors - add destination field |
| Create `SourceDataConfig(PathConfig)` | Scopes config to sources only (sinks don't route validation failures) |

---

## Current Codebase Structure

**Config hierarchy (config_base.py):**
```
PluginConfig
    └── DataPluginConfig (requires schema)
            └── PathConfig (adds path validation)
                    └── CSVSourceConfig (per-source config)
                    └── JSONSourceConfig (per-source config)
```

**Existing validation infrastructure:**
- `PluginContext.record_validation_error()` → records to audit trail
- `ValidationErrorToken` → returned when error recorded
- `LandscapeRecorder.record_validation_error()` → persists to DB
- `validation_errors_table` → schema in landscape

---

## Scope

**In scope:**
- Create `SourceDataConfig(PathConfig)` with `on_validation_failure`
- Update `CSVSourceConfig`, `JSONSourceConfig` to extend `SourceDataConfig`
- Add `destination` field to existing validation error recording
- Implement sink routing for quarantined rows

**Out of scope:**
- Transform error routing (WP-11.99b)
- Creating new event types (extend existing `ValidationErrorToken`)

**Depends on:** WP-11.99 (config-driven schemas, `record_validation_error`)
**Risk:** Low - extends existing infrastructure

---

## Task 1: Create SourceDataConfig

**Files:**
- Modify: `src/elspeth/plugins/config_base.py`
- Test: `tests/plugins/test_config_base.py`

**Step 1: Write failing tests**

Add to `tests/plugins/test_config_base.py`:

```python
"""Tests for source quarantine configuration."""

import pytest
from pydantic import ValidationError


class TestSourceDataConfig:
    """Tests for SourceDataConfig with on_validation_failure."""

    def test_on_validation_failure_required(self) -> None:
        """on_validation_failure must be explicitly specified."""
        from elspeth.plugins.config_base import SourceDataConfig

        with pytest.raises(ValidationError) as exc_info:
            SourceDataConfig(
                path="data.csv",
                schema_config=None,  # Will fail DataPluginConfig validation too
            )

        # Should fail because on_validation_failure is required
        errors = exc_info.value.errors()
        field_names = [e["loc"][0] for e in errors]
        assert "on_validation_failure" in field_names

    def test_on_validation_failure_accepts_sink_name(self) -> None:
        """on_validation_failure accepts a sink name."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.config_base import SourceDataConfig

        config = SourceDataConfig(
            path="data.csv",
            schema_config=SchemaConfig(fields=["id: int", "name: str"], mode="strict"),
            on_validation_failure="quarantine_sink",
        )

        assert config.on_validation_failure == "quarantine_sink"

    def test_on_validation_failure_accepts_discard(self) -> None:
        """on_validation_failure accepts 'discard' for explicit /dev/null."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.config_base import SourceDataConfig

        config = SourceDataConfig(
            path="data.csv",
            schema_config=SchemaConfig(fields=["id: int"], mode="free"),
            on_validation_failure="discard",
        )

        assert config.on_validation_failure == "discard"

    def test_on_validation_failure_rejects_empty_string(self) -> None:
        """on_validation_failure rejects empty string."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.config_base import SourceDataConfig

        with pytest.raises(ValidationError):
            SourceDataConfig(
                path="data.csv",
                schema_config=SchemaConfig(fields=["id: int"], mode="strict"),
                on_validation_failure="",
            )

    def test_source_config_inherits_path_and_schema(self) -> None:
        """SourceDataConfig inherits path and schema_config requirements."""
        from elspeth.contracts.schema import SchemaConfig
        from elspeth.plugins.config_base import SourceDataConfig

        config = SourceDataConfig(
            path="data/input.csv",
            schema_config=SchemaConfig(fields=["name: str"], mode="strict"),
            on_validation_failure="bad_rows",
        )

        assert config.path == "data/input.csv"
        assert config.schema_config is not None
        assert config.schema_config.mode == "strict"
```

**Step 2: Implement SourceDataConfig**

Add to `config_base.py` after `PathConfig`:

```python
class SourceDataConfig(PathConfig):
    """Base config for source plugins with quarantine routing.

    Extends PathConfig to add required on_validation_failure field.
    All sources must specify where non-conformant rows go.
    """

    on_validation_failure: str = Field(
        ...,  # Required - no default
        description="Sink name for non-conformant rows, or 'discard' for explicit drop",
    )

    @field_validator("on_validation_failure")
    @classmethod
    def validate_on_validation_failure(cls, v: str) -> str:
        """Ensure on_validation_failure is not empty."""
        if not v or not v.strip():
            raise ValueError("on_validation_failure must be a sink name or 'discard'")
        return v.strip()
```

**Step 3: Run tests and commit**

```bash
pytest tests/plugins/test_config_base.py::TestSourceDataConfig -v
git add src/elspeth/plugins/config_base.py tests/plugins/test_config_base.py
git commit -m "$(cat <<'EOF'
feat(config): add SourceDataConfig with on_validation_failure

Sources must now explicitly specify where non-conformant rows go.
Accepts sink name or 'discard' for explicit /dev/null behavior.
No hidden defaults - operator must acknowledge bad data handling.

Part of WP-11.99a: Quarantine Sink Configuration

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 2: Update Source Configs to Use SourceDataConfig

**Files:**
- Modify: `src/elspeth/plugins/sources/csv_source.py`
- Modify: `src/elspeth/plugins/sources/json_source.py`
- Test: Existing tests should fail until config updated

**Step 1: Update CSVSourceConfig**

Change:
```python
# OLD:
class CSVSourceConfig(PathConfig):

# NEW:
class CSVSourceConfig(SourceDataConfig):
```

**Step 2: Update JSONSourceConfig similarly**

Change:
```python
# OLD:
class JSONSourceConfig(PathConfig):

# NEW:
class JSONSourceConfig(SourceDataConfig):
```

**Step 3: Run existing tests (expect failures)**

```bash
pytest tests/plugins/sources/ -v
```

Expected: Tests fail because `on_validation_failure` now required.

**Step 4: Update test fixtures to include on_validation_failure**

Update test configs to include the required field:

```python
# Example fixture update:
config = {
    "path": "test.csv",
    "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
    "on_validation_failure": "discard",  # Add this
}
```

**Step 5: Run tests and commit**

```bash
pytest tests/plugins/sources/ -v
git add src/elspeth/plugins/sources/csv_source.py src/elspeth/plugins/sources/json_source.py tests/
git commit -m "$(cat <<'EOF'
refactor(sources): use SourceDataConfig for quarantine routing

CSVSourceConfig and JSONSourceConfig now extend SourceDataConfig.
This requires on_validation_failure in all source configurations.

Part of WP-11.99a: Quarantine Sink Configuration

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 3: Extend ValidationErrorToken with Destination

**Files:**
- Modify: `src/elspeth/plugins/context.py`
- Modify: `src/elspeth/core/landscape/recorder.py`
- Modify: `src/elspeth/core/landscape/schema.py`
- Test: `tests/plugins/test_context.py`, `tests/core/landscape/test_recorder.py`

**Step 1: Add destination to ValidationErrorToken**

In `context.py`, update the dataclass:

```python
@dataclass
class ValidationErrorToken:
    """Token returned when recording a validation error.

    Allows tracking the quarantined row through the audit trail.
    """

    row_id: str
    node_id: str
    error_id: str | None = None  # Set if recorded to landscape
    destination: str = "discard"  # Sink name or "discard"
```

**Step 2: Update record_validation_error signature**

In `context.py`, update the method:

```python
def record_validation_error(
    self,
    row: dict[str, Any],
    error: str,
    schema_mode: str,
    destination: str,  # NEW: required parameter
) -> ValidationErrorToken:
    """Record a validation error for audit trail.

    Called by sources when row validation fails. The row will be
    quarantined (not processed further) but the error is recorded
    for complete audit coverage.

    Args:
        row: The row data that failed validation
        error: Description of the validation failure
        schema_mode: "strict", "free", or "dynamic"
        destination: Sink name where row is routed, or "discard"

    Returns:
        ValidationErrorToken for tracking the quarantined row
    """
    from elspeth.core.canonical import stable_hash

    row_id = str(row["id"]) if "id" in row else stable_hash(row)[:16]

    if self.landscape is None:
        logger.warning(
            "Validation error not recorded (no landscape): %s",
            error,
        )
        return ValidationErrorToken(
            row_id=row_id,
            node_id=self.node_id or "unknown",
            destination=destination,
        )

    error_id = self.landscape.record_validation_error(
        run_id=self.run_id,
        node_id=self.node_id,
        row_data=row,
        error=error,
        schema_mode=schema_mode,
        destination=destination,  # NEW
    )

    return ValidationErrorToken(
        row_id=row_id,
        node_id=self.node_id or "unknown",
        error_id=error_id,
        destination=destination,
    )
```

**Step 3: Update LandscapeRecorder.record_validation_error**

In `recorder.py`, add destination parameter and column:

```python
def record_validation_error(
    self,
    run_id: str,
    node_id: str | None,
    row_data: dict[str, Any],
    error: str,
    schema_mode: str,
    destination: str,  # NEW
) -> str:
    """Record a validation error in the audit trail.

    Args:
        run_id: Current run ID
        node_id: Node where validation failed
        row_data: The row that failed validation
        error: Error description
        schema_mode: Schema mode ("strict", "free", "dynamic")
        destination: Where row was routed ("discard" or sink name)

    Returns:
        error_id for tracking
    """
    error_id = f"verr_{_generate_id()[:12]}"

    with self._db.connection() as conn:
        conn.execute(
            validation_errors_table.insert().values(
                error_id=error_id,
                run_id=run_id,
                node_id=node_id,
                row_hash=stable_hash(row_data),
                row_data_json=canonical_json(row_data),
                error=error,
                schema_mode=schema_mode,
                destination=destination,  # NEW
                created_at=_now(),
            )
        )

    return error_id
```

**Step 4: Add destination column to schema**

In `schema.py`, add column to `validation_errors_table`:

```python
# Add to validation_errors_table definition:
Column("destination", String(255), nullable=False),  # sink name or "discard"
```

**Step 5: Write tests and commit**

```bash
pytest tests/plugins/test_context.py tests/core/landscape/test_recorder.py -v
git add src/elspeth/plugins/context.py src/elspeth/core/landscape/recorder.py src/elspeth/core/landscape/schema.py tests/
git commit -m "$(cat <<'EOF'
feat(landscape): add destination to validation error recording

ValidationErrorToken now tracks where quarantined rows are routed.
Destination is recorded in audit trail for complete traceability.

Part of WP-11.99a: Quarantine Sink Configuration

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 4: Implement Quarantine Routing in Sources

**Files:**
- Modify: `src/elspeth/plugins/sources/csv_source.py`
- Modify: `src/elspeth/plugins/sources/json_source.py`
- Test: `tests/plugins/sources/test_quarantine_routing.py`

**Step 1: Write tests for quarantine routing**

Create `tests/plugins/sources/test_quarantine_routing.py`:

```python
"""Tests for source quarantine routing."""

import pytest
from unittest.mock import MagicMock, patch
from pathlib import Path
import tempfile


class TestSourceQuarantineRouting:
    """Tests for routing non-conformant rows to quarantine sink."""

    def test_valid_rows_yielded_normally(self, tmp_path: Path) -> None:
        """Valid rows are yielded from load()."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext

        csv_file = tmp_path / "valid.csv"
        csv_file.write_text("id,name\n1,Alice\n2,Bob\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "bad_rows",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")
        rows = list(source.load(ctx))

        assert len(rows) == 2
        assert rows[0]["id"] == 1
        assert rows[0]["name"] == "Alice"

    def test_invalid_row_not_yielded(self, tmp_path: Path) -> None:
        """Invalid rows are NOT yielded from load()."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext

        csv_file = tmp_path / "mixed.csv"
        csv_file.write_text("id,name\n1,Alice\nnot_int,Bob\n3,Charlie\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "discard",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")
        rows = list(source.load(ctx))

        # Only valid rows yielded
        assert len(rows) == 2
        assert rows[0]["id"] == 1
        assert rows[1]["id"] == 3

    def test_validation_error_recorded_with_destination(self, tmp_path: Path) -> None:
        """Validation errors record the configured destination."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext

        csv_file = tmp_path / "bad.csv"
        csv_file.write_text("id,name\nnot_int,Alice\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "quarantine_sink",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")

        # Mock record_validation_error to capture call
        recorded_errors = []
        original_record = ctx.record_validation_error

        def capture_record(row, error, schema_mode, destination):
            recorded_errors.append({
                "row": row,
                "destination": destination,
            })
            return original_record(row, error, schema_mode, destination)

        ctx.record_validation_error = capture_record

        list(source.load(ctx))  # Consume iterator

        assert len(recorded_errors) == 1
        assert recorded_errors[0]["destination"] == "quarantine_sink"

    def test_discard_destination_recorded(self, tmp_path: Path) -> None:
        """'discard' is recorded as destination, not omitted."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext

        csv_file = tmp_path / "bad.csv"
        csv_file.write_text("id,name\nnot_int,Alice\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "discard",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")

        recorded_destinations = []

        def capture_record(row, error, schema_mode, destination):
            recorded_destinations.append(destination)
            from elspeth.plugins.context import ValidationErrorToken
            return ValidationErrorToken(row_id="test", node_id="csv", destination=destination)

        ctx.record_validation_error = capture_record

        list(source.load(ctx))

        assert recorded_destinations == ["discard"]

    def test_route_to_sink_called_for_non_discard(self, tmp_path: Path) -> None:
        """ctx.route_to_sink called when destination is not 'discard'."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext, ValidationErrorToken

        csv_file = tmp_path / "bad.csv"
        csv_file.write_text("id,name\nnot_int,Alice\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "quarantine_sink",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")

        # Mock route_to_sink
        routed_rows = []
        ctx.route_to_sink = lambda sink_name, row, metadata: routed_rows.append({
            "sink": sink_name,
            "row": row,
        })

        # Mock record_validation_error
        ctx.record_validation_error = lambda row, error, schema_mode, destination: \
            ValidationErrorToken(row_id="test", node_id="csv", destination=destination)

        list(source.load(ctx))

        assert len(routed_rows) == 1
        assert routed_rows[0]["sink"] == "quarantine_sink"
        assert routed_rows[0]["row"]["name"] == "Alice"

    def test_route_to_sink_not_called_for_discard(self, tmp_path: Path) -> None:
        """ctx.route_to_sink NOT called when destination is 'discard'."""
        from elspeth.plugins.sources.csv_source import CSVSource
        from elspeth.plugins.context import PluginContext, ValidationErrorToken

        csv_file = tmp_path / "bad.csv"
        csv_file.write_text("id,name\nnot_int,Alice\n")

        source = CSVSource({
            "path": str(csv_file),
            "schema": {"fields": ["id: int", "name: str"], "mode": "strict"},
            "on_validation_failure": "discard",
        })

        ctx = PluginContext(run_id="test-run", config={}, node_id="csv_source")

        routed = []
        ctx.route_to_sink = lambda sink_name, row, metadata: routed.append(sink_name)
        ctx.record_validation_error = lambda row, error, schema_mode, destination: \
            ValidationErrorToken(row_id="test", node_id="csv", destination=destination)

        list(source.load(ctx))

        assert routed == []  # Nothing routed for discard
```

**Step 2: Add route_to_sink to PluginContext**

In `context.py`, add the routing method:

```python
def route_to_sink(
    self,
    sink_name: str,
    row: dict[str, Any],
    metadata: dict[str, Any] | None = None,
) -> None:
    """Route a row to a named sink.

    Used for quarantined rows that need to go to a specific sink
    rather than continuing through the pipeline.

    Args:
        sink_name: Name of the sink to route to
        row: Row data to send
        metadata: Optional metadata (e.g., quarantine_reason)

    Note:
        In Phase 2, this logs a warning. Phase 3 engine will implement
        actual routing via the SDA orchestrator.
    """
    if metadata is None:
        metadata = {}

    # Phase 2: Log for now, Phase 3 will route via orchestrator
    logger.info(
        "Routing row to sink %s (Phase 3 will implement): metadata=%s",
        sink_name,
        metadata,
    )

    # TODO Phase 3: self.orchestrator.route_to_sink(sink_name, row, metadata)
```

**Step 3: Update CSVSource.load() to use quarantine routing**

In `csv_source.py`, update the load method:

```python
def load(self, ctx: PluginContext) -> Iterator[dict[str, Any]]:
    """Load rows from CSV file.

    Each row is validated against the configured schema:
    - Valid rows are yielded for processing
    - Invalid rows are quarantined and routed to on_validation_failure destination

    Yields:
        Dict for each valid row with column names as keys.

    Raises:
        FileNotFoundError: If CSV file does not exist.
    """
    if not self._path.exists():
        raise FileNotFoundError(f"CSV file not found: {self._path}")

    self._dataframe = pd.read_csv(
        self._path,
        delimiter=self._delimiter,
        encoding=self._encoding,
        skiprows=self._skip_rows,
        dtype=str,
        keep_default_na=False,
    )

    for record in self._dataframe.to_dict(orient="records"):
        row = {str(k): v for k, v in record.items()}

        try:
            validated = self._schema_class.model_validate(row)
            yield validated.to_row()
        except ValidationError as e:
            # Record validation failure with destination
            ctx.record_validation_error(
                row=row,
                error=str(e),
                schema_mode=self._schema_config.mode or "dynamic",
                destination=self._on_validation_failure,  # NEW
            )

            # Route to sink if not discarding
            if self._on_validation_failure != "discard":
                ctx.route_to_sink(
                    sink_name=self._on_validation_failure,
                    row=row,
                    metadata={"validation_error": str(e)},
                )

            # Don't yield - row is quarantined
            continue
```

Also update `__init__` to store the config:

```python
def __init__(self, config: dict[str, Any]) -> None:
    super().__init__(config)
    cfg = CSVSourceConfig.from_dict(config)

    self._path = cfg.resolved_path()
    self._delimiter = cfg.delimiter
    self._encoding = cfg.encoding
    self._skip_rows = cfg.skip_rows
    self._on_validation_failure = cfg.on_validation_failure  # NEW
    # ... rest unchanged
```

**Step 4: Update JSONSource similarly**

Apply the same pattern to `json_source.py`.

**Step 5: Run tests and commit**

```bash
pytest tests/plugins/sources/test_quarantine_routing.py -v
git add src/elspeth/plugins/sources/ src/elspeth/plugins/context.py tests/
git commit -m "$(cat <<'EOF'
feat(sources): implement quarantine routing for invalid rows

Sources now route validation failures to configured destination.
- Record error with destination in audit trail
- Route to sink if not 'discard'
- Complete audit coverage even for dropped rows

Part of WP-11.99a: Quarantine Sink Configuration

Co-Authored-By: Claude Opus 4.5 <noreply@anthropic.com>
EOF
)"
```

---

## Task 5: Final Verification

**Step 1: Run mypy**

```bash
mypy src/elspeth/plugins/config_base.py src/elspeth/plugins/sources/ src/elspeth/plugins/context.py src/elspeth/core/landscape/recorder.py --strict
```

**Step 2: Run all tests**

```bash
pytest tests/plugins/ tests/core/landscape/ -v
```

**Step 3: Verify destination is always recorded**

```bash
# Check all record_validation_error calls include destination
grep -rn "record_validation_error" src/elspeth/plugins/ --include="*.py"
```

---

## Verification Checklist

- [ ] `SourceDataConfig` created with required `on_validation_failure`
- [ ] `CSVSourceConfig` and `JSONSourceConfig` extend `SourceDataConfig`
- [ ] `ValidationErrorToken` includes `destination` field
- [ ] `record_validation_error` takes and persists `destination`
- [ ] `validation_errors_table` has `destination` column
- [ ] `ctx.route_to_sink()` method exists (Phase 2 stub)
- [ ] Sources route to sink when destination != "discard"
- [ ] All tests pass, mypy clean

---

## Files Changed Summary

| File | Change Type | Description |
|------|-------------|-------------|
| `src/elspeth/plugins/config_base.py` | MODIFY | Add `SourceDataConfig` class |
| `src/elspeth/plugins/sources/csv_source.py` | MODIFY | Use `SourceDataConfig`, add routing |
| `src/elspeth/plugins/sources/json_source.py` | MODIFY | Use `SourceDataConfig`, add routing |
| `src/elspeth/plugins/context.py` | MODIFY | Add `destination` to `ValidationErrorToken`, add `route_to_sink` |
| `src/elspeth/core/landscape/recorder.py` | MODIFY | Add `destination` parameter |
| `src/elspeth/core/landscape/schema.py` | MODIFY | Add `destination` column |
| `tests/plugins/test_config_base.py` | MODIFY | Add `TestSourceDataConfig` |
| `tests/plugins/sources/test_quarantine_routing.py` | CREATE | Routing behavior tests |

---

## Configuration Example

```yaml
sources:
  customer_data:
    type: csv_source
    path: data/customers.csv
    schema:
      mode: strict
      fields:
        - "id: int"
        - "name: str"
        - "email: str"
    on_validation_failure: bad_customer_rows  # Sink name

sinks:
  bad_customer_rows:
    type: json_sink
    path: output/quarantine/customers.jsonl
```

Or for explicit discard:

```yaml
sources:
  log_stream:
    type: json_source
    path: logs/*.json
    schema:
      mode: free
      fields:
        - "timestamp: str"
    on_validation_failure: discard  # Explicit: we don't care about malformed logs
```

---

## Dependency Notes

- **Depends on:** WP-11.99 (config-driven schemas, `record_validation_error` infrastructure)
- **Unlocks:** Complete source-level audit trail with routing
- **Risk:** Low - extends existing infrastructure
- **Estimated Effort:** 2-3 hours
