{
  "$schema": "https://example.com/forensic-audit.schema.json",
  "metadata": {
    "repo": "Elspeth",
    "commit": "4baac2d2b38fcaa631d990d2b21aab3bd754c0b7",
    "generated_at": "2025-10-19T01:13:00Z",
    "auditor": "Forensic Code Auditor",
    "overall_verdict": "ACCEPT"
  },
  "scores": {
    "security": 8,
    "reliability": 7,
    "maintainability": 7,
    "test_hygiene": 8,
    "operations": 7,
    "build_release": 9,
    "documentation": 8
  },
  "gates": [
    {
      "gate": "tests_pass",
      "status": "PASS",
      "evidence": ".github/workflows/ci.yml pytest job; coverage.xml present"
    },
    {
      "gate": "coverage_threshold",
      "status": "PASS",
      "target": "\u226585% line (mission-critical)",
      "observed": "86.9% line; 72.1% branch (coverage.xml)"
    },
    {
      "gate": "secrets_scan_clean",
      "status": "PASS",
      "evidence": "CI gitleaks configured; manual patterns search shows no real secrets"
    },
    {
      "gate": "sbom_vulns",
      "status": "PASS",
      "summary": "pip-audit clean on requirements.lock; SBOM generated"
    },
    {
      "gate": "reproducible_build",
      "status": "PASS",
      "evidence": "Lockfiles with hashes; piptools sync in CI and bootstrap"
    },
    {
      "gate": "container_hygiene",
      "status": "N/A",
      "evidence": "No containers/IaC present"
    },
    {
      "gate": "observability_minimums",
      "status": "PASS",
      "evidence": "Structured JSONL logs for plugins"
    }
  ],
  "findings": [
    {
      "id": "AUD-0001",
      "title": "Runtime dependency versions rely on lockfiles; pyproject uses open lower bounds",
      "category": "dependency",
      "severity": "HIGH",
      "confidence_wep": "Highly likely",
      "impact": "If teams install via pyproject constraints (>=) without syncing lockfiles, environments may drift and introduce unvetted versions despite CI using locks.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "pyproject.toml:14",
          "start_line": 14,
          "end_line": 43,
          "excerpt": "dependencies = [ 'azure-identity>=1.25.0', 'requests>=2.32.0', ... ]"
        },
        {
          "path": "scripts/bootstrap.sh:18",
          "start_line": 18,
          "end_line": 28,
          "excerpt": "pip install --require-hashes -r requirements-dev.lock; piptools sync"
        }
      ],
      "recommendation": "Mandate locked installs (pip\u2011tools sync + --require\u2011hashes) for all envs; avoid unpinned installs from pyproject in runtime paths.",
      "proposed_patch": "*** Begin Patch\n*** Update File: README.md\n@@\n-Activate the environment when working manually (locked installs only):\n+Activate the environment with locked installs (mandatory for all environments):\n@@\n-python -m piptools sync requirements-dev.lock\n-pip install -e . --no-deps\n+python -m piptools sync requirements-dev.lock\n+pip install -e . --no-deps\n+\n+Note: Do not install from pyproject.toml constraints directly; always sync from the lockfile to ensure reproducible builds.\n*** End Patch",
      "effort": "S",
      "links": [
        "https://pip-tools.readthedocs.io/en/latest/"
      ],
      "tags": [
        "reproducibility",
        "resolved",
        "supply-chain"
      ]
    },
    {
      "id": "AUD-0002",
      "title": "Checkpoint file writes are not synchronised under parallel execution",
      "category": "reliability",
      "severity": "MEDIUM",
      "confidence_wep": "Likely",
      "impact": "Concurrent writes to the checkpoint file in threaded mode may interleave on some filesystems, risking lost or corrupt lines and incorrect resumptions.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "src/elspeth/core/experiments/runner.py:712",
          "start_line": 712,
          "end_line": 714,
          "excerpt": "with path.open('a', encoding='utf-8') as handle: handle.write(...)"
        },
        {
          "path": "src/elspeth/core/experiments/runner.py:600",
          "start_line": 600,
          "end_line": 660,
          "excerpt": "ThreadPoolExecutor(...); executor.submit(worker, data)"
        }
      ],
      "recommendation": "Guard checkpoint appends with a threading.Lock or single-writer queue in parallel mode.",
      "proposed_patch": "*** Begin Patch\n*** Update File: src/elspeth/core/experiments/runner.py\n@@\n     def _append_checkpoint(self, path: Path, row_id: str) -> None:\n-        with path.open(\"a\", encoding=\"utf-8\") as handle:\n-            handle.write(f\"{row_id}\\n\")\n+        if not hasattr(self, \"_checkpoint_lock\"):\n+            import threading\n+            self._checkpoint_lock = threading.Lock()  # type: ignore[attr-defined]\n+        with self._checkpoint_lock:  # type: ignore[attr-defined]\n+            with path.open(\"a\", encoding=\"utf-8\") as handle:\n+                handle.write(f\"{row_id}\\n\")\n*** End Patch",
      "effort": "S",
      "tags": [
        "concurrency",
        "io",
        "resolved"
      ]
    },
    {
      "id": "AUD-0003",
      "title": "Plugin JSONL logging lacks synchronisation; potential interleaved lines",
      "category": "operations",
      "severity": "LOW",
      "confidence_wep": "Likely",
      "impact": "Concurrent writes from multiple plugins in a single run can interleave JSONL entries, complicating automated parsing during incident response.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "src/elspeth/core/utils/logging.py:360",
          "start_line": 360,
          "end_line": 372,
          "excerpt": "with open(self.log_file, 'a', encoding='utf-8') as f: f.write(...)"
        }
      ],
      "recommendation": "Add a per-process file lock (threading.Lock) around writes; optionally buffer and flush in batches.",
      "proposed_patch": "*** Begin Patch\n*** Update File: src/elspeth/core/utils/logging.py\n@@\n     def __init__(\n@@\n-        self._log_initialization()\n+        self._log_initialization()\n+        # Serialise file appends across threads\n+        import threading\n+        self._file_lock = threading.Lock()\n@@\n     def _write_log_entry(self, entry: dict[str, Any]) -> None:\n@@\n-        try:\n-            with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n-                f.write(json.dumps(entry) + \"\\n\")\n+        try:\n+            with self._file_lock:\n+                with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n+                    f.write(json.dumps(entry) + \"\\n\")\n*** End Patch",
      "effort": "S",
      "tags": [
        "concurrency",
        "observability",
        "resolved"
      ]
    },
    {
      "id": "AUD-0004",
      "title": "No HTTP retry/backoff for Azure Content Safety middleware",
      "category": "reliability",
      "severity": "MEDIUM",
      "confidence_wep": "Highly likely",
      "impact": "Transient network errors or 5xx from Azure Content Safety will fail the request or cause unnecessary aborts/skip without bounded retries, reducing resilience.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "src/elspeth/plugins/nodes/transforms/llm/middleware/azure_content_safety.py:102",
          "start_line": 92,
          "end_line": 104,
          "excerpt": "response = requests.post(...); response.raise_for_status()"
        }
      ],
      "recommendation": "Add 3 attempts with exponential backoff and jitter for idempotent screening calls.",
      "proposed_patch": "*** Begin Patch\n*** Update File: src/elspeth/plugins/nodes/transforms/llm/middleware/azure_content_safety.py\n@@\n-        response = requests.post(url, headers=headers, json=payload, timeout=10)\n-        response.raise_for_status()\n+        attempts, delay = 0, 0.5\n+        while True:\n+            attempts += 1\n+            try:\n+                response = requests.post(url, headers=headers, json=payload, timeout=10)\n+                response.raise_for_status()\n+                break\n+            except Exception:\n+                if attempts >= 3:\n+                    raise\n+                import time, random\n+                time.sleep(delay + random.random() * 0.2)\n+                delay *= 2\n*** End Patch",
      "effort": "S",
      "tags": [
        "network",
        "resolved",
        "retries"
      ]
    },
    {
      "id": "AUD-0005",
      "title": "Repository sinks use requests without retry; risk of flaky uploads",
      "category": "reliability",
      "severity": "MEDIUM",
      "confidence_wep": "Likely",
      "impact": "GitHub/Azure DevOps uploads can fail transiently (429/5xx). Without adapter\u2011level retries, pipeline runs may fail unnecessarily.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "src/elspeth/plugins/nodes/sinks/repository.py:256",
          "start_line": 256,
          "end_line": 263,
          "excerpt": "response = self.session.request(...); raise RuntimeError on bad status"
        }
      ],
      "recommendation": "Mount an HTTPAdapter with urllib3 Retry on the session (e.g., 3 attempts on connect/read/status for 429/5xx).",
      "proposed_patch": "*** Begin Patch\n*** Update File: src/elspeth/plugins/nodes/sinks/repository.py\n@@\n     def __post_init__(self) -> None:\n-        if self.session is None:\n-            self.session = requests.Session()\n+        if self.session is None:\n+            self.session = requests.Session()\n+            try:\n+                from requests.adapters import HTTPAdapter\n+                from urllib3.util.retry import Retry\n+                retry = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504], allowed_methods=[\"GET\",\"PUT\",\"POST\"])\n+                adapter = HTTPAdapter(max_retries=retry)\n+                self.session.mount(\"https://\", adapter)\n+                self.session.mount(\"http://\", adapter)\n+            except Exception:\n+                pass\n*** End Patch",
      "effort": "S",
      "tags": [
        "network",
        "resolved",
        "retries"
      ]
    },
    {
      "id": "AUD-0006",
      "title": "Environment-based endpoint overrides should not relax allow-lists in STRICT/STANDARD",
      "category": "security",
      "severity": "MEDIUM",
      "confidence_wep": "Likely",
      "impact": "Allowing ELSPETH_APPROVED_ENDPOINTS to add patterns in stricter modes can weaken exfiltration controls if set incorrectly in production environments.",
      "likelihood": "Low",
      "evidence": [
        {
          "path": "src/elspeth/core/security/approved_endpoints.py:70",
          "start_line": 70,
          "end_line": 110,
          "excerpt": "_get_environment_patterns() returns patterns unconditionally"
        }
      ],
      "recommendation": "Ignore ELSPETH_APPROVED_ENDPOINTS unless in DEVELOPMENT mode; log a warning otherwise.",
      "proposed_patch": "*** Begin Patch\n*** Update File: src/elspeth/core/security/approved_endpoints.py\n@@\n-def _get_environment_patterns() -> list[str]:\n+def _get_environment_patterns() -> list[str]:\n@@\n-    env_patterns = os.environ.get(\"ELSPETH_APPROVED_ENDPOINTS\", \"\").strip()\n+    # Only allow env overrides in DEVELOPMENT mode to prevent policy drift\n+    if get_secure_mode() != SecureMode.DEVELOPMENT:\n+        return []\n+    env_patterns = os.environ.get(\"ELSPETH_APPROVED_ENDPOINTS\", \"\").strip()\n*** End Patch",
      "effort": "S",
      "tags": [
        "endpoint-allowlist",
        "policy",
        "resolved"
      ]
    },
    {
      "id": "AUD-0007",
      "title": "Broad exception handling in critical paths risks masking actionable errors",
      "category": "maintainability",
      "severity": "LOW",
      "confidence_wep": "Likely",
      "impact": "\u2018except Exception\u2019 in LLM retry and plugin execution can conceal underlying error categories that deserve distinct handling or telemetry.",
      "likelihood": "Medium",
      "evidence": [
        {
          "path": "src/elspeth/core/experiments/runner.py:630",
          "start_line": 620,
          "end_line": 640,
          "excerpt": "except Exception as exc: ..."
        },
        {
          "path": "src/elspeth/plugins/nodes/sinks/visual_report.py:153",
          "start_line": 144,
          "end_line": 156,
          "excerpt": "except Exception as exc: ..."
        }
      ],
      "recommendation": "Narrow exceptions where possible (e.g., requests.RequestException, JSONDecodeError) and tag error_type in metrics.",
      "effort": "M",
      "tags": [
        "error-handling"
      ]
    }
  ],
  "quick_wins": [
    "AUD-0002",
    "AUD-0003",
    "AUD-0004",
    "AUD-0005",
    "AUD-0006"
  ],
  "blockers": [],
  "conditions_for_acceptance": []
}