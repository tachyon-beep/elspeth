# Colour → Animal Association Run

This example drives a locally hosted OpenAI-compatible model (running on `http://192.168.1.240:5000`) to suggest an animal for each colour in a 100-row CSV.

## Prerequisites

1. Ensure the service is reachable at `http://192.168.1.240:5000/v1/chat/completions` and accepts the standard OpenAI Chat Completions schema.
2. Install project dependencies:

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -e .[dev,analytics-visual]  # pulls matplotlib/seaborn for visuals[^colour-visual-deps-2025-10-12]
   ```

## Dataset

The CSV lives at `config/data/colour_animals.csv` with three columns:

| colour        | tone   | season |
|---------------|--------|--------|
| red           | dark   | autumn |
| blue          | dark   | winter |
| mint green    | light  | spring |
| …             | …      | …      |

The extra `tone` and `season` columns drive multi-dimensional templating.

## Settings profile

`config/settings_colour_animals.yaml` defines:

- `datasource`: local CSV reader pointing at the dataset.
- `llm`: new `http_openai` plugin aimed at the local endpoint.
- `sinks`: CSV sink writing to `outputs/colour_animals/latest_results.csv`.
- Prompts: the system instructs concise answers, and the user prompt uses conditional logic to tailor guidance while enforcing a strict output format. For example:

  ```jinja2
  {% set tone_descriptor = "bright" if tone == "light" else "deep" if tone == "dark" else "balanced" %}
  {% if season == "winter" %}
  The colour "{{ colour }}" is a {{ tone_descriptor }} winter hue. Name an animal adapted to cold climates...
  {% elif season == "summer" %}
  ...
  {% endif %}
  Respond with **only** the animal name in Title Case, no extra words or punctuation.
  ```

  This demonstrates how multiple dataset dimensions can shape the final prompt.

## Running the job

```bash
source .venv/bin/activate
python -m elspeth.cli \
  --settings config/settings_colour_animals.yaml \
  --profile colour_animals \
  --single-run \
  --output-csv outputs/colour_animals/run_results.csv \
  --head 0
```

- The CLI loads all 100 rows, calls the local model, and writes rows + LLM completions to the chosen CSV.
- The default sink also emits `outputs/colour_animals/latest_results.csv` for convenience.
<!-- UPDATE 2025-10-12: To observe retry metadata, set `retry.max_attempts` within `config/settings_colour_animals.yaml`; CLI previews surface `retry_attempts` columns generated by `src/elspeth/cli.py:103`. -->
- For resilience and observability, add retry/middleware options to the profile:

  ```yaml
  retry:
    max_attempts: 3
    initial_delay: 1.0
    backoff_multiplier: 2.0
  llm_middlewares:
    - name: prompt_shield
      options:
        denied_terms: ["internal", "classified"]
        on_violation: mask
    - name: health_monitor
      options:
        heartbeat_interval: 30
  ```

  Retry metadata then appears as `retry_attempts`/`retry_max_attempts` in CLI previews and CSV outputs, while middleware logs feed the structured channels described in logging standards.[^colour-middleware-2025-10-12]

## Optional reporting

To produce consolidated reports instead (Markdown/JSON/Excel/PNG), first install pandas + openpyxl + matplotlib as above, then run:[^colour-reporting-2025-10-12]

```bash
python -m elspeth.cli \
  --settings config/settings_colour_animals.yaml \
  --profile colour_animals \
  --reports-dir outputs/colour_animals/reports \
  --single-run \
  --head 0
```

If the endpoint requires a bearer token, expose it via environment variable and reference it with `api_key_env` in the settings file.
<!-- UPDATE 2025-10-12: Consider adding a `rate_limiter` definition if the local gateway enforces quotas; the Azure-compatible `adaptive` limiter is available via `src/elspeth/core/controls/registry.py:45`. -->
<!-- UPDATE 2025-10-12: Enable the `analytics_visual` sink (install via `pip install -e .[dev,analytics-visual]`) to generate PNG/HTML charts alongside CSV outputs when comparing colour responses. -->
- Add an `analytics_report` or `analytics_visual` sink alongside the CSV sink to capture retry summaries, failure samples, and charts for accreditation evidence:

  ```yaml
  sinks:
    - plugin: csv
      options:
        path: outputs/colour_animals/latest_results.csv
    - plugin: analytics_report
      options:
        base_path: outputs/colour_animals/analytics
    - plugin: visual_report
      options:
        base_path: outputs/colour_animals/visual
        formats: ["png", "html"]
  ```

  Review the generated JSON/Markdown/PNG artefacts in `outputs/colour_animals/analytics` and `outputs/colour_animals/visual` when assembling accreditation packages.[^colour-analytics-2025-10-12]

## Update History

- 2025-10-12 – Documented retry/rate-limit tweaks for the colour→animal example, noted optional analytics/visual sinks, and confirmed reporting workflow alignment.
- 2025-10-12 – Update 2025-10-12: Added dependency and reporting cross-references for the colour example.

[^colour-reporting-2025-10-12]: Update 2025-10-12: Reporting workflow mirrors docs/reporting-and-suite-management.md (Section 2).
[^colour-middleware-2025-10-12]: Update 2025-10-12: Middleware guidance aligns with docs/architecture/security-controls.md (Middleware Safeguards) and docs/logging-standards.md.
[^colour-analytics-2025-10-12]: Update 2025-10-12: Analytics sink usage tied to docs/architecture/security-controls.md (Analytics provenance) and docs/reporting-and-suite-management.md (Artefact overview).
