# Plugin Catalogue & Interface Matrix

| Type | Plugin Name | Implementation | Key Options | Security / Validation | Coverage |
| --- | --- | --- | --- | --- | --- |
| Datasource | `azure_blob` | `src/elspeth/plugins/datasources/blob.py:17` | `config_path`, `profile`, `on_error`, `security_level` | Normalises classification, supports `on_error=skip` for resilience (`src/elspeth/plugins/datasources/blob.py:24`) | `tests/test_datasource_blob_plugin.py` |
| Datasource | `csv_blob` | `src/elspeth/plugins/datasources/csv_blob.py:17` | `path`, `dtype`, `encoding`, `on_error`, `security_level` | Persists security level on returned DataFrame; warning logs on skips (`src/elspeth/plugins/datasources/csv_blob.py:35`) | `tests/test_datasource_csv.py` |
| Datasource | `local_csv` | `src/elspeth/plugins/datasources/csv_local.py:17` | `path`, `dtype`, `encoding`, `on_error`, `security_level` | Fail-fast for missing data; attaches security attribute (`src/elspeth/plugins/datasources/csv_local.py:35`) | `tests/test_datasource_csv.py` |
| LLM Client | `azure_openai` | `src/elspeth/plugins/llms/azure_openai.py:11` | `config` (api credentials), `deployment`, `temperature`, `max_tokens` | Reads secrets from env, raises on missing config (`src/elspeth/plugins/llms/azure_openai.py:60`) | `tests/test_llm_azure.py` |
| LLM Client | `http_openai` | `src/elspeth/plugins/llms/openai_http.py:11` | `api_base`, `api_key/env`, `model`, `timeout` | Uses `requests` with bearer auth; enforces TLS/HTTP errors (`src/elspeth/plugins/llms/openai_http.py:43`) | `tests/test_llm_http_openai.py` |
| LLM Client | `mock` | `src/elspeth/plugins/llms/mock.py:11` | `seed` | Deterministic scoring for offline suites (`src/elspeth/plugins/llms/mock.py:12`) | `tests/test_llm_mock.py` |
| Middleware | `audit_logger` | `src/elspeth/plugins/llms/middleware.py:70` | `include_prompts`, `channel` | Structured logging of requests/responses | `tests/test_llm_middleware.py:39` |
| Middleware | `prompt_shield` | `src/elspeth/plugins/llms/middleware.py:91` | `denied_terms`, `mask`, `on_violation`, `channel` | Blocks/masks on policy violations (`src/elspeth/plugins/llms/middleware.py:110`) | `tests/test_llm_middleware.py:63` |
| Middleware | `azure_content_safety` | `src/elspeth/plugins/llms/middleware.py:206` | `endpoint`, `key/_env`, `severity_threshold`, `on_violation`, `on_error` | Screens prompts via Azure Content Safety API (`src/elspeth/plugins/llms/middleware.py:232`) | `tests/test_llm_middleware.py:141` |
| Middleware | `health_monitor` | `src/elspeth/plugins/llms/middleware.py:124` | `heartbeat_interval`, `stats_window`, `include_latency` | Emits heartbeat telemetry with latency stats | `tests/test_llm_middleware.py:39` (through middleware chain) |
| Middleware | `azure_environment` | `src/elspeth/plugins/llms/middleware_azure.py:76` | `enable_run_logging`, `log_prompts`, `severity_threshold`, `on_error` | Integrates with Azure ML runs; warns when context missing (`src/elspeth/plugins/llms/middleware_azure.py:102`) | `tests/test_llm_middleware.py:11` |
| Sink | `azure_blob` | `src/elspeth/plugins/outputs/blob.py:33` | `config_path`, `profile`, `path_template`, `include_manifest`, `credential/_env`, `on_error` | Uploads results/manifests with classification metadata (`src/elspeth/plugins/outputs/blob.py:78`) | `tests/test_outputs_blob.py` |
| Sink | `csv` | `src/elspeth/plugins/outputs/csv_file.py:18` | `path`, `overwrite`, `sanitize_formulas`, `sanitize_guard`, `on_error` | Escapes dangerous prefixes; records sanitiser config (`src/elspeth/plugins/outputs/csv_file.py:59`) | `tests/test_outputs_csv.py` |
| Sink | `excel_workbook` | `src/elspeth/plugins/outputs/excel.py:26` | `base_path`, `timestamped`, `sanitize_formulas`, `include_manifest`, `include_aggregates` | Sanitises cells, captures manifest metadata (`src/elspeth/plugins/outputs/excel.py:99`) | `tests/test_outputs_local_bundle.py` (shared patterns) |
| Sink | `local_bundle` | `src/elspeth/plugins/outputs/local_bundle.py` | `base_path`, `bundle_name`, `timestamped`, `write_json/csv` | Creates local JSON/CSV bundles with sanitisation options | `tests/test_outputs_local_bundle.py` |
| Sink | `zip_bundle` | `src/elspeth/plugins/outputs/zip_bundle.py` | `base_path`, `bundle_name`, `include_manifest`, `include_results` | Produces zipped artifacts for offline review | `tests/test_outputs_archival.py` |
| Sink | `file_copy` | `src/elspeth/plugins/outputs/file_copy.py` | `destination`, `overwrite` | Controlled artifact duplication honoring security levels | `tests/test_sink_chaining.py` |
| Sink | `signed_artifact` | `src/elspeth/plugins/outputs/signed.py:20` | `base_path`, `bundle_name`, `key/_env`, `algorithm`, `on_error` | HMAC signature & manifest for tamper evidence (`src/elspeth/plugins/outputs/signed.py:48`) | `tests/test_outputs_signed.py:21` |
| Sink | `github_repo` / `azure_devops_repo` | `src/elspeth/plugins/outputs/repository.py:84` | `owner/repo/branch` or `organization/project/repository`, `token_env`, `dry_run` | Dry-run payloads, base64 commit uploads (`src/elspeth/plugins/outputs/repository.py:135`) | `tests/test_outputs_repo.py` |
| Sink | `analytics_report` | `src/elspeth/plugins/outputs/analytics_report.py` | `base_path`, `formats`, `include_metadata/aggregates` | Generates JSON/Markdown analytics bundles | `tests/test_outputs_analytics_report.py` |
| Controls | `fixed_window` limiter | `src/elspeth/core/controls/rate_limit.py:61` | `requests`, `per_seconds` | Thread-safe window enforcement | `tests/test_controls.py` |
| Controls | `adaptive` limiter | `src/elspeth/core/controls/rate_limit.py:104` | `requests_per_minute`, `tokens_per_minute` | Token-aware throttling | `tests/test_controls.py` |
| Controls | `fixed_price` tracker | `src/elspeth/core/controls/cost_tracker.py:36` | `prompt_token_price`, `completion_token_price` | Aggregates usage and cost summary | `tests/test_controls.py` |
| Experiment Row | `score_extractor` | `src/elspeth/plugins/experiments/metrics.py:37` | `key`, `criteria`, `threshold` | Normalises per-criteria metrics; flags thresholds | `tests/test_experiment_metrics_plugins.py` |
| Experiment Aggregator | `score_stats`, `score_recommendation`, `score_distribution` etc. | `src/elspeth/plugins/experiments/metrics.py:108` | Plugin-specific statistical knobs | Provide statistical baselines | `tests/test_experiment_metrics_plugins.py` |
| Early-stop | `threshold` | `src/elspeth/plugins/experiments/early_stop.py:17` | `metric`, `threshold`, `comparison`, `min_rows` | Stops runs on configurable criteria | `tests/test_suite_runner_integration.py` |
| Validation | `regex_match`, `json`, `llm_guard` | `src/elspeth/plugins/experiments/validation.py:20` | Regex flags, JSON shape enforcement, validator LLM | Blocks malformed or non-compliant responses | `tests/test_validation_plugins.py` |

**Registration validation** â€“ All plugins are resolved via schema-aware registries (`src/elspeth/core/registry.py:91`, `src/elspeth/core/experiments/plugin_registry.py:102`, `src/elspeth/core/controls/registry.py:36`), ensuring misconfigured options fail fast during configuration loading (`src/elspeth/core/validation.py:271`). For hardened deployments, restrict available plugins by loading only approved modules prior to invoking the CLI.
